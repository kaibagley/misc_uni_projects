{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80f34e2",
   "metadata": {},
   "source": [
    "# Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf98ea2",
   "metadata": {},
   "source": [
    "Kai Bagley - 21984315"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6737fb3",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d78a87",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7423b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import spacy\n",
    "from spacy.matcher import Matcher, DependencyMatcher\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef921b5e",
   "metadata": {},
   "source": [
    "#### Load JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ab55a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"./frames.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a583b908",
   "metadata": {},
   "source": [
    "##### Main Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e90f237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>turns</th>\n",
       "      <th>wizard_id</th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U22HTHYNP</td>\n",
       "      <td>[{'text': 'I'd like to book a trip to Atlantis...</td>\n",
       "      <td>U21DKG18C</td>\n",
       "      <td>e2c0fc6c-2134-4891-8353-ef16d8412c9a</td>\n",
       "      <td>{'userSurveyRating': 4.0, 'wizardSurveyTaskSuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U21E41CQP</td>\n",
       "      <td>[{'text': 'Hello, I am looking to book a vacat...</td>\n",
       "      <td>U21DMV0KA</td>\n",
       "      <td>4a3bfa39-2c22-42c8-8694-32b4e34415e9</td>\n",
       "      <td>{'userSurveyRating': 3.0, 'wizardSurveyTaskSuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U21RP4FCY</td>\n",
       "      <td>[{'text': 'Hello there i am looking to go on a...</td>\n",
       "      <td>U21E0179B</td>\n",
       "      <td>6e67ed28-e94c-4fab-96b6-68569a92682f</td>\n",
       "      <td>{'userSurveyRating': 2.0, 'wizardSurveyTaskSuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U22HTHYNP</td>\n",
       "      <td>[{'text': 'Hi I'd like to go to Caprica from B...</td>\n",
       "      <td>U21DKG18C</td>\n",
       "      <td>5ae76e50-5b48-4166-9f6d-67aaabd7bcaa</td>\n",
       "      <td>{'userSurveyRating': 5.0, 'wizardSurveyTaskSuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U21E41CQP</td>\n",
       "      <td>[{'text': 'Hello, I am looking to book a trip ...</td>\n",
       "      <td>U21DMV0KA</td>\n",
       "      <td>24603086-bb53-431e-a0d8-1dcc63518ba9</td>\n",
       "      <td>{'userSurveyRating': 5.0, 'wizardSurveyTaskSuc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id                                              turns  wizard_id  \\\n",
       "0  U22HTHYNP  [{'text': 'I'd like to book a trip to Atlantis...  U21DKG18C   \n",
       "1  U21E41CQP  [{'text': 'Hello, I am looking to book a vacat...  U21DMV0KA   \n",
       "2  U21RP4FCY  [{'text': 'Hello there i am looking to go on a...  U21E0179B   \n",
       "3  U22HTHYNP  [{'text': 'Hi I'd like to go to Caprica from B...  U21DKG18C   \n",
       "4  U21E41CQP  [{'text': 'Hello, I am looking to book a trip ...  U21DMV0KA   \n",
       "\n",
       "                                     id  \\\n",
       "0  e2c0fc6c-2134-4891-8353-ef16d8412c9a   \n",
       "1  4a3bfa39-2c22-42c8-8694-32b4e34415e9   \n",
       "2  6e67ed28-e94c-4fab-96b6-68569a92682f   \n",
       "3  5ae76e50-5b48-4166-9f6d-67aaabd7bcaa   \n",
       "4  24603086-bb53-431e-a0d8-1dcc63518ba9   \n",
       "\n",
       "                                              labels  \n",
       "0  {'userSurveyRating': 4.0, 'wizardSurveyTaskSuc...  \n",
       "1  {'userSurveyRating': 3.0, 'wizardSurveyTaskSuc...  \n",
       "2  {'userSurveyRating': 2.0, 'wizardSurveyTaskSuc...  \n",
       "3  {'userSurveyRating': 5.0, 'wizardSurveyTaskSuc...  \n",
       "4  {'userSurveyRating': 5.0, 'wizardSurveyTaskSuc...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8a9094",
   "metadata": {},
   "source": [
    "##### Main -> Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b4ec58",
   "metadata": {},
   "source": [
    "`userSurveyRating` that shows the users satisfaction, from 1 - 5.\n",
    "`wizardSurveyTaskSuccessful` is a boolean value, shows whether or not the user's goal was successful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097e18ab",
   "metadata": {},
   "source": [
    "##### Main -> Turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f895ccd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'text': 'I'd like to book a trip to Atlantis ...</td>\n",
       "      <td>{'text': 'Hi...I checked a few options for you...</td>\n",
       "      <td>{'text': 'Yes, how about going to Neverland fr...</td>\n",
       "      <td>{'text': 'I checked the availability for this ...</td>\n",
       "      <td>{'text': 'I have no flexibility for dates... b...</td>\n",
       "      <td>{'text': 'I checked the availability for that ...</td>\n",
       "      <td>{'text': 'I suppose I'll speak with my husband...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'text': 'Hello, I am looking to book a vacati...</td>\n",
       "      <td>{'text': 'Hi. Sorry, I can't find any trips fr...</td>\n",
       "      <td>{'text': 'What about a trip from Gotham City t...</td>\n",
       "      <td>{'text': 'Sorry, I cannot find any trips leavi...</td>\n",
       "      <td>{'text': 'Would any packages to Mos Eisley be ...</td>\n",
       "      <td>{'text': 'There are no trips available to Mos ...</td>\n",
       "      <td>{'text': 'You know what, I'd like to try and v...</td>\n",
       "      <td>{'text': 'I cannot find any trips available to...</td>\n",
       "      <td>{'text': 'Do you have any trips from Gotham Ci...</td>\n",
       "      <td>{'text': 'I can book you a 3 day trip to Kobe ...</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'text': 'Hello there i am looking to go on a ...</td>\n",
       "      <td>{'text': 'when  would you like to travel and h...</td>\n",
       "      <td>{'text': 'Not sure when we want to leave, but ...</td>\n",
       "      <td>{'text': 'do you have a budget?', 'author': 'w...</td>\n",
       "      <td>{'text': 'yes i do, it is around $2200', 'auth...</td>\n",
       "      <td>{'text': 'where will you be travelling from?',...</td>\n",
       "      <td>{'text': 'We are from Neverland', 'author': 'u...</td>\n",
       "      <td>{'text': 'We have nothing available leaving fr...</td>\n",
       "      <td>{'text': 'we can depart from Toronto', 'author...</td>\n",
       "      <td>{'text': 'Gotham City is not a destination we ...</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'text': 'Hi I'd like to go to Caprica from Bu...</td>\n",
       "      <td>{'text': 'And what would be your maximum budge...</td>\n",
       "      <td>{'text': 'Actually it's unlimited for this tri...</td>\n",
       "      <td>{'text': 'How many adults and how many childre...</td>\n",
       "      <td>{'text': '2 adults', 'author': 'user', 'timest...</td>\n",
       "      <td>{'text': 'I have no trips to Caprica from Busa...</td>\n",
       "      <td>{'text': 'Do you have anything for San Antonio...</td>\n",
       "      <td>{'text': 'Yes, I do.  I have one for 8445.37 U...</td>\n",
       "      <td>{'text': 'Is breakfast included?', 'author': '...</td>\n",
       "      <td>{'text': 'Yes, it is.', 'author': 'wizard', 't...</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'text': 'Hello, I am looking to book a trip f...</td>\n",
       "      <td>{'text': 'I have several options available wit...</td>\n",
       "      <td>{'text': 'I do not have any dates in mind. I w...</td>\n",
       "      <td>{'text': 'I can book 7 days at a 4.0 star hote...</td>\n",
       "      <td>{'text': 'Do these packages have different dep...</td>\n",
       "      <td>{'text': 'The 3.0 star trip leaves Kochi Augus...</td>\n",
       "      <td>{'text': 'Ok, I would like to purchase the tri...</td>\n",
       "      <td>{'text': 'Perfect, I will book that trip for y...</td>\n",
       "      <td>{'text': 'Thank you', 'author': 'user', 'times...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0   \\\n",
       "0  {'text': 'I'd like to book a trip to Atlantis ...   \n",
       "1  {'text': 'Hello, I am looking to book a vacati...   \n",
       "2  {'text': 'Hello there i am looking to go on a ...   \n",
       "3  {'text': 'Hi I'd like to go to Caprica from Bu...   \n",
       "4  {'text': 'Hello, I am looking to book a trip f...   \n",
       "\n",
       "                                                  1   \\\n",
       "0  {'text': 'Hi...I checked a few options for you...   \n",
       "1  {'text': 'Hi. Sorry, I can't find any trips fr...   \n",
       "2  {'text': 'when  would you like to travel and h...   \n",
       "3  {'text': 'And what would be your maximum budge...   \n",
       "4  {'text': 'I have several options available wit...   \n",
       "\n",
       "                                                  2   \\\n",
       "0  {'text': 'Yes, how about going to Neverland fr...   \n",
       "1  {'text': 'What about a trip from Gotham City t...   \n",
       "2  {'text': 'Not sure when we want to leave, but ...   \n",
       "3  {'text': 'Actually it's unlimited for this tri...   \n",
       "4  {'text': 'I do not have any dates in mind. I w...   \n",
       "\n",
       "                                                  3   \\\n",
       "0  {'text': 'I checked the availability for this ...   \n",
       "1  {'text': 'Sorry, I cannot find any trips leavi...   \n",
       "2  {'text': 'do you have a budget?', 'author': 'w...   \n",
       "3  {'text': 'How many adults and how many childre...   \n",
       "4  {'text': 'I can book 7 days at a 4.0 star hote...   \n",
       "\n",
       "                                                  4   \\\n",
       "0  {'text': 'I have no flexibility for dates... b...   \n",
       "1  {'text': 'Would any packages to Mos Eisley be ...   \n",
       "2  {'text': 'yes i do, it is around $2200', 'auth...   \n",
       "3  {'text': '2 adults', 'author': 'user', 'timest...   \n",
       "4  {'text': 'Do these packages have different dep...   \n",
       "\n",
       "                                                  5   \\\n",
       "0  {'text': 'I checked the availability for that ...   \n",
       "1  {'text': 'There are no trips available to Mos ...   \n",
       "2  {'text': 'where will you be travelling from?',...   \n",
       "3  {'text': 'I have no trips to Caprica from Busa...   \n",
       "4  {'text': 'The 3.0 star trip leaves Kochi Augus...   \n",
       "\n",
       "                                                  6   \\\n",
       "0  {'text': 'I suppose I'll speak with my husband...   \n",
       "1  {'text': 'You know what, I'd like to try and v...   \n",
       "2  {'text': 'We are from Neverland', 'author': 'u...   \n",
       "3  {'text': 'Do you have anything for San Antonio...   \n",
       "4  {'text': 'Ok, I would like to purchase the tri...   \n",
       "\n",
       "                                                  7   \\\n",
       "0                                               None   \n",
       "1  {'text': 'I cannot find any trips available to...   \n",
       "2  {'text': 'We have nothing available leaving fr...   \n",
       "3  {'text': 'Yes, I do.  I have one for 8445.37 U...   \n",
       "4  {'text': 'Perfect, I will book that trip for y...   \n",
       "\n",
       "                                                  8   \\\n",
       "0                                               None   \n",
       "1  {'text': 'Do you have any trips from Gotham Ci...   \n",
       "2  {'text': 'we can depart from Toronto', 'author...   \n",
       "3  {'text': 'Is breakfast included?', 'author': '...   \n",
       "4  {'text': 'Thank you', 'author': 'user', 'times...   \n",
       "\n",
       "                                                  9   ...    38    39    40  \\\n",
       "0                                               None  ...  None  None  None   \n",
       "1  {'text': 'I can book you a 3 day trip to Kobe ...  ...  None  None  None   \n",
       "2  {'text': 'Gotham City is not a destination we ...  ...  None  None  None   \n",
       "3  {'text': 'Yes, it is.', 'author': 'wizard', 't...  ...  None  None  None   \n",
       "4                                               None  ...  None  None  None   \n",
       "\n",
       "     41    42    43    44    45    46    47  \n",
       "0  None  None  None  None  None  None  None  \n",
       "1  None  None  None  None  None  None  None  \n",
       "2  None  None  None  None  None  None  None  \n",
       "3  None  None  None  None  None  None  None  \n",
       "4  None  None  None  None  None  None  None  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.json_normalize(df.turns).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844e30c4",
   "metadata": {},
   "source": [
    "##### Main -> Turns -> Labels -> Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01468532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info</th>\n",
       "      <th>frame_id</th>\n",
       "      <th>requests</th>\n",
       "      <th>frame_parent_id</th>\n",
       "      <th>binary_questions</th>\n",
       "      <th>compare_requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'intent': [{'val': 'book', 'negated': False}]...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                info  frame_id requests  \\\n",
       "0  {'intent': [{'val': 'book', 'negated': False}]...         1       []   \n",
       "\n",
       "  frame_parent_id binary_questions compare_requests  \n",
       "0            None               []               []  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.turns[0][0][\"labels\"][\"frames\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a993ea13",
   "metadata": {},
   "source": [
    "Above is the `labels` -> `frames` structure, which is present in every single turn. This is shown above. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb13171",
   "metadata": {},
   "source": [
    "The general structure of the `frames.json` file is shown above, with each row being a different instance of interaction between a wizard and a user. `user_id`, `wizard_id` and `id` are pretty self-explanatory, and `labels` is a user review, and a task success indicator.\n",
    "\n",
    "`turns` is where the conversation is stored, along with all the information gleaned by the wizard from the user, and any bookings the wizard could/couldn't find in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f470fb",
   "metadata": {},
   "source": [
    "#### What's the structure of a conversation in the `frames.json` file? Display it as a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85d37fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>author</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>db</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'd like to book a trip to Atlantis from Capri...</td>\n",
       "      <td>{'acts': [{'args': [{'val': 'book', 'key': 'in...</td>\n",
       "      <td>user</td>\n",
       "      <td>1.471272e+12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi...I checked a few options for you, and unfo...</td>\n",
       "      <td>{'acts': [{'args': [{'val': [{'annotations': [...</td>\n",
       "      <td>wizard</td>\n",
       "      <td>1.471272e+12</td>\n",
       "      <td>{'result': [[{'trip': {'returning': {'duration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, how about going to Neverland from Caprica...</td>\n",
       "      <td>{'acts': [{'args': [{'val': 'Neverland', 'key'...</td>\n",
       "      <td>user</td>\n",
       "      <td>1.471273e+12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I checked the availability for this date and t...</td>\n",
       "      <td>{'acts': [{'args': [{'val': [{'annotations': [...</td>\n",
       "      <td>wizard</td>\n",
       "      <td>1.471273e+12</td>\n",
       "      <td>{'result': [[], [], [], [], [], []], 'search':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have no flexibility for dates... but I can l...</td>\n",
       "      <td>{'acts': [{'args': [{'val': False, 'key': 'fle...</td>\n",
       "      <td>user</td>\n",
       "      <td>1.471273e+12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I checked the availability for that date and t...</td>\n",
       "      <td>{'acts': [{'args': [{'val': [{'annotations': [...</td>\n",
       "      <td>wizard</td>\n",
       "      <td>1.471273e+12</td>\n",
       "      <td>{'result': [[]], 'search': [{'ORIGIN_CITY': 'A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I suppose I'll speak with my husband to see if...</td>\n",
       "      <td>{'acts': [{'args': [], 'name': 'thankyou'}], '...</td>\n",
       "      <td>user</td>\n",
       "      <td>1.471273e+12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  I'd like to book a trip to Atlantis from Capri...   \n",
       "1  Hi...I checked a few options for you, and unfo...   \n",
       "2  Yes, how about going to Neverland from Caprica...   \n",
       "3  I checked the availability for this date and t...   \n",
       "4  I have no flexibility for dates... but I can l...   \n",
       "5  I checked the availability for that date and t...   \n",
       "6  I suppose I'll speak with my husband to see if...   \n",
       "\n",
       "                                              labels  author     timestamp  \\\n",
       "0  {'acts': [{'args': [{'val': 'book', 'key': 'in...    user  1.471272e+12   \n",
       "1  {'acts': [{'args': [{'val': [{'annotations': [...  wizard  1.471272e+12   \n",
       "2  {'acts': [{'args': [{'val': 'Neverland', 'key'...    user  1.471273e+12   \n",
       "3  {'acts': [{'args': [{'val': [{'annotations': [...  wizard  1.471273e+12   \n",
       "4  {'acts': [{'args': [{'val': False, 'key': 'fle...    user  1.471273e+12   \n",
       "5  {'acts': [{'args': [{'val': [{'annotations': [...  wizard  1.471273e+12   \n",
       "6  {'acts': [{'args': [], 'name': 'thankyou'}], '...    user  1.471273e+12   \n",
       "\n",
       "                                                  db  \n",
       "0                                                NaN  \n",
       "1  {'result': [[{'trip': {'returning': {'duration...  \n",
       "2                                                NaN  \n",
       "3  {'result': [[], [], [], [], [], []], 'search':...  \n",
       "4                                                NaN  \n",
       "5  {'result': [[]], 'search': [{'ORIGIN_CITY': 'A...  \n",
       "6                                                NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.turns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83208fa3",
   "metadata": {},
   "source": [
    "Above is the structure of the first conversation in the `frames` file. Each line represents a message sent between the user and the wizard, shown by column `author`. `text` is the message itself, `labels` contains all of the arguments, acts and intents, including the previous frames created throughout the conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71e5c25",
   "metadata": {},
   "source": [
    "#### What are the unique intents recorded in the file? What is the distribution of intents?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30f6f3e",
   "metadata": {},
   "source": [
    "We can see the intent for each message sent by any user, we will look at every turn. These can be found as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c528ddf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val': 'book', 'negated': False}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.turns[116][4][\"labels\"][\"frames\"][0][\"info\"][\"intent\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60062a31",
   "metadata": {},
   "source": [
    "And we can find a list of unique instances, and plot these (one intent per frame):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eab7880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_list = [] \n",
    "\n",
    "for dialogue in df.turns:\n",
    "    # Iterate over all conversations\n",
    "    # Find last turn, and access list of frames\n",
    "    frames = dialogue[-1][\"labels\"][\"frames\"]\n",
    "    for frame in frames:\n",
    "        # iterate over every frame created in the conv\n",
    "        info = frame[\"info\"]\n",
    "        if \"intent\" in info:\n",
    "            intent_list.append(info[\"intent\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87c075a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dict_values([{'val': 'book', 'negated': False}, {'val': 'book', 'negated': True}])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[{x[\"negated\"]:x for x in intent_list}.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f6e5f3",
   "metadata": {},
   "source": [
    "The unique intents are shown above, where all intents are related to \"book\", and are either negated or not.\n",
    "\n",
    "The intents are binomially distributed, as they can only be book, or not book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de73c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the intent_list plottable\n",
    "intent_plt = []\n",
    "\n",
    "for intent in intent_list:\n",
    "    intent_plt.append(int(intent[\"negated\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a9ea1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist(intent_plt, log=True, bins=2)\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_xticklabels([\"Make a booking\", \"Don't make a booking\"])\n",
    "ax.set_title(\"Binomial histogram of intents\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63e2772",
   "metadata": {},
   "source": [
    "Above is a histogram representing the binomial distribution of the intents of every act in the corpus.\n",
    "\n",
    "We can also plot the Dialogue Act Frequency to give us a more interesting plot than the above one. There is one or more dialogue acts per turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "532216dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['args', 'name'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all acts\n",
    "df.turns[0][3][\"labels\"][\"acts\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8748db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_list = [] \n",
    "\n",
    "for dialogue in df.turns:\n",
    "    # Iterate over all conversations\n",
    "    for turn in dialogue:\n",
    "        # Iterate over every turn\n",
    "        acts = turn[\"labels\"][\"acts\"]\n",
    "        for act in acts:\n",
    "            # Iterate over every act\n",
    "            if \"name\" in act:\n",
    "                act_list.append(act[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aafe0657",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_counts = pd.DataFrame(act_list).value_counts()\n",
    "act_counts.index = [x[0] for x in act_counts.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b0697d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "nbins = len(set(act_list))\n",
    "\n",
    "ax = act_counts.plot(kind=\"barh\")\n",
    "ax.set_title(\"Dialogue Act Freq.\")\n",
    "ax.set_ylabel(\"Dialogue Act\")\n",
    "ax.xaxis.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1933972",
   "metadata": {},
   "source": [
    "#### Find queries of each difficulty in the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f145a",
   "metadata": {},
   "source": [
    "Low difficulty queries include a known destination, inflexible time period, budget and amount of people. \n",
    "\n",
    "Medium difficulty queries have one flexible parameter, and may need the number of travelers clarified.\n",
    "\n",
    "Hard difficulty has even more flexibility, and user requests comparison of packages.\n",
    "\n",
    "We will only check the first utterance of each dialogue, which corresponds to the first frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "561736d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. :  1369\n",
      "easy:  3\n",
      "med :  14\n",
      "hard:  1352\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "easy  = 0\n",
    "med   = 0\n",
    "hard  = 0\n",
    "\n",
    "easy_ix = []\n",
    "\n",
    "def flex_count(frame_info, keys):\n",
    "    \n",
    "    flex = 0\n",
    "    if \"budget\" not in keys or frame_info[\"budget\"][0][\"val\"] == -1:\n",
    "        flex += 1\n",
    "    if \"or_city\" not in keys or frame_info[\"or_city\"][0] == -1:\n",
    "        flex += 1\n",
    "    if \"dst_city\" not in keys or frame_info[\"dst_city\"][0] == -1:\n",
    "        flex += 1\n",
    "    if \"str_date\" not in keys or frame_info[\"str_date\"][0] == -1:\n",
    "        flex += 1\n",
    "    if \"end_date\" not in keys or frame_info[\"end_date\"][0] == -1:\n",
    "        flex += 1\n",
    "    if \"n_adults\" not in keys or frame_info[\"n_adults\"][0][\"val\"] == -1:\n",
    "        flex += 1\n",
    "    if \"n_children\" not in keys or frame_info[\"n_children\"][0][\"val\"] == -1:\n",
    "        flex += 1\n",
    "        \n",
    "    return flex\n",
    "\n",
    "def check_easy(frame_info):\n",
    "    keys = frame_info.keys()\n",
    "    \n",
    "    # Must have no flexibility\n",
    "    if flex_count(frame_info, keys) != 0:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def check_med(frame_info):\n",
    "    keys = frame_info.keys()\n",
    "    \n",
    "    # Only need one flexible thing\n",
    "    if flex_count(frame_info, keys) == 1:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "    \n",
    "def check_hard(frame_info):\n",
    "    keys = frame_info.keys()\n",
    "    \n",
    "    # Need more than one flexible thing\n",
    "    if flex_count(frame_info, keys) >= 2:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "for (i, dialogue) in enumerate(df.turns):\n",
    "    frame = dialogue[0][\"labels\"][\"frames\"][0]\n",
    "    frame_info = frame[\"info\"]\n",
    "\n",
    "    count += 1\n",
    "    \n",
    "    if check_easy(frame_info):\n",
    "        easy += 1\n",
    "        easy_ix.append(i)\n",
    "        continue\n",
    "    if check_med(frame_info):\n",
    "        med += 1\n",
    "        continue\n",
    "    if check_hard(frame_info) or frame[\"compare_requests\"] != []:\n",
    "        hard += 1\n",
    "        continue\n",
    "\n",
    "print(\"no. : \", count)\n",
    "print(\"easy: \", easy)\n",
    "print(\"med : \", med)\n",
    "print(\"hard: \", hard)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bb7e99",
   "metadata": {},
   "source": [
    "#### Vocabulary and Word Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe8b064",
   "metadata": {},
   "source": [
    "We will find a list of all words, only including alphanumeric values (no punctuation), and no stop words.\n",
    "\n",
    "The reason I am removing the punctuation and stop words is becasue the vocabularies will have a lot of almost meaningless symbols, and the word frequency will just have extremely common stopwords such as \"the\" and \"a\", etc. I though this might not be as informative it could be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73282541",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/home/kaiba/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - '/home/kaiba/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This method isn't too slow, but seems just as fast as \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# using pandas applymap and stuff\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# And since there isn't quite too many words, I'll just \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# make a huge list of them all\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m stopwords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstopwords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      7\u001b[0m user_text \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m wiz_text  \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/home/kaiba/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# This method isn't too slow, but seems just as fast as \n",
    "# using pandas applymap and stuff\n",
    "\n",
    "# And since there isn't quite too many words, I'll just \n",
    "# make a huge list of them all\n",
    "stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "user_text = []\n",
    "wiz_text  = []\n",
    "\n",
    "for dialogue in df.turns:\n",
    "    for (i, turn) in enumerate(dialogue):\n",
    "        tokens = word_tokenize(turn[\"text\"])\n",
    "        # Set to lowercase\n",
    "        tokens = [token.lower() for token in tokens if token.isalnum()]\n",
    "        # Remove stopwords\n",
    "        tokens = [token for token in tokens if not token in stopwords]\n",
    "        if i%2 == 0:\n",
    "            # dialogue alternates between user and wiz,\n",
    "            # starting with user\n",
    "            user_text += tokens\n",
    "            continue\n",
    "        wiz_text += tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1bf75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"User vocab: \", len(set(user_text)))\n",
    "print(\"Wizard vocab: \", len(set(wiz_text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9e00e9",
   "metadata": {},
   "source": [
    "Vocabularies consist of 3797 unique words for the users, and 2229 unique words for the wizards.\n",
    "\n",
    "Now we can find the frequency distributions, without any punctuation or stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b35f823f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m userfd_mc \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mFreqDist(\u001b[43muser_text\u001b[49m)\u001b[38;5;241m.\u001b[39mmost_common(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      2\u001b[0m wizfd_mc  \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mFreqDist(wiz_text)\u001b[38;5;241m.\u001b[39mmost_common(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'user_text' is not defined"
     ]
    }
   ],
   "source": [
    "userfd_mc = nltk.FreqDist(user_text).most_common(10)\n",
    "wizfd_mc  = nltk.FreqDist(wiz_text).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1481ca87",
   "metadata": {},
   "source": [
    "We will plot the 10 most common words in the whole corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6844d69a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'userfd_mc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      3\u001b[0m y_pos \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbarh(y_pos, [x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43muserfd_mc\u001b[49m], align\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_yticks(y_pos)\n\u001b[1;32m      7\u001b[0m axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_yticklabels([x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m userfd_mc])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'userfd_mc' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(9, 4))\n",
    "\n",
    "y_pos = np.arange(10)\n",
    "\n",
    "axs[0].barh(y_pos, [x[1] for x in userfd_mc], align=\"center\")\n",
    "axs[0].set_yticks(y_pos)\n",
    "axs[0].set_yticklabels([x[0] for x in userfd_mc])\n",
    "axs[0].set_xlabel(\"Word Count\")\n",
    "axs[0].set_title(\"For Users\")\n",
    "\n",
    "axs[1].barh(y_pos, [x[1] for x in wizfd_mc], align=\"center\")\n",
    "axs[1].set_yticks(y_pos)\n",
    "axs[1].set_yticklabels([x[0] for x in wizfd_mc])\n",
    "axs[1].set_xlabel(\"Word Count\")\n",
    "axs[1].set_title(\"For Wizards\")\n",
    "\n",
    "fig.tight_layout(pad=3)\n",
    "fig.suptitle(\"Freq. Dist. for 10 Most Common Words:\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf381f79",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8d273e",
   "metadata": {},
   "source": [
    "Consider the following pre-processing steps, and report vocabulary size for users and wizards, respectively, after each step:\n",
    "\n",
    "* Tokenize\n",
    "* Lemmatize and compare with stemming\n",
    "* Retokenize frequent noun phrases\n",
    "* Remove stop words (rank words according TF/IDF)\n",
    "\n",
    "We will start from scratch in this section, ignoring whatever manipulation I've done in the section before this one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443acb39",
   "metadata": {},
   "source": [
    "#### Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bfe0ca",
   "metadata": {},
   "source": [
    "First, I will create two lists, one for user turnn and one for wizard turns. These lists will have one element for each dialogue in the dataset, and each element in the lists will be the concatenated texts authored by the user OR the wizard.\n",
    "\n",
    "So we will have a user corpus, and a wizard corpus, where each doc in the corpora will be a turn written by the respective author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd1f7460",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_text = []\n",
    "wizd_text = []\n",
    "\n",
    "for dialogue in df.turns:\n",
    "    for (i, turn) in enumerate(dialogue):\n",
    "        text = turn[\"text\"].lower()\n",
    "        if i%2 == 0:\n",
    "            # dialogue alternates between user and wiz,\n",
    "            # starting with user\n",
    "            user_text.append(text)\n",
    "            continue\n",
    "        wizd_text.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a708b4ed",
   "metadata": {},
   "source": [
    "We will keep all pipes active in the `nlp` object, as we will need them done later, and we can still access the output at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6573435e",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     31\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     37\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/util.py:427\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 427\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01eab0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_corpus = list(nlp.pipe(user_text))\n",
    "wizd_corpus = list(nlp.pipe(wizd_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b37d07",
   "metadata": {},
   "source": [
    "We can find the vocab after the tokenization pipe in the pipeline below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "202ec888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User vocab size  :  4155\n",
      "Wizard vocab size:  4742\n"
     ]
    }
   ],
   "source": [
    "def find_vocab_tok(corpus):\n",
    "    vocab = set()\n",
    "    for doc in corpus:\n",
    "        vocab.update({token.text for token in doc})\n",
    "    return vocab\n",
    "    \n",
    "print(\"User vocab size  : \", len(find_vocab_tok(user_corpus)))\n",
    "print(\"Wizard vocab size: \", len(find_vocab_tok(wizd_corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e72660",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d88567",
   "metadata": {},
   "source": [
    "The `nlp` pipeline in the tokenization step handles lemmatization as well, and to see the lemmas we just look at the `lemma_` attribute of each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca65bb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User vocab size  :  3613\n",
      "Wizard vocab size:  4406\n"
     ]
    }
   ],
   "source": [
    "def find_vocab_lem(corpus):\n",
    "    vocab = set()\n",
    "    for doc in corpus:\n",
    "        vocab.update({token.lemma_ for token in doc})\n",
    "    return vocab\n",
    "\n",
    "print(\"User vocab size  : \", len(find_vocab_lem(user_corpus)))\n",
    "print(\"Wizard vocab size: \", len(find_vocab_lem(wizd_corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eebcaa",
   "metadata": {},
   "source": [
    "Stemming involves reducing a word down to its root form by removing letters, which may not necessarily be a dictionary word. For example:\n",
    "\n",
    "* \"study\" -> \"studi\"\n",
    "* \"studying\" -> \"studi\"\n",
    "* \"studies\" -> \"studi\"\n",
    "\n",
    "Lemmatization means reducing words down to their first form based on context in a sentence, which will be a dictionary word. For example: \n",
    "\n",
    "* \"study\" -> \"study\" \n",
    "* \"studying\" -> \"studying\"\n",
    "* \"studies\" -> \"study\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e067c7",
   "metadata": {},
   "source": [
    "#### Retokenizing Frequent Noun Phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b1cc2a",
   "metadata": {},
   "source": [
    "Will search both user and wizard corpora as one to find frequent noun phrases, since both corpora will be discussing the same topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ac939e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find noun phrases\n",
    "noun_phrases = []\n",
    "for corpus in [user_corpus, wizd_corpus]:\n",
    "    for doc in corpus:\n",
    "        noun_phrases += [chunk.text for chunk in doc.noun_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bca4487",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_fd = nltk.FreqDist(noun_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49265c5c",
   "metadata": {},
   "source": [
    "Since we are looking for the frequent noun phrases ones, we will choose the cutoff to be 100, such that the phrase must occur more than 100 times in the entire text data for it to be considered frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c243a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even though it looks bad it doesn't seem slow\n",
    "freq_noun_phrases = [x for x in np_fd if np_fd[x]>100]\n",
    "for corpus in [user_corpus, wizd_corpus]:\n",
    "    for doc in corpus:\n",
    "        with doc.retokenize() as retok:\n",
    "            for chunk in doc.noun_chunks:\n",
    "                if chunk.text in freq_noun_phrases:\n",
    "                    retok.merge(chunk)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db77029e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User vocab size  :  4187\n",
      "Wizard vocab size:  4776\n"
     ]
    }
   ],
   "source": [
    "print(\"User vocab size  : \", len(find_vocab_tok(user_corpus)))\n",
    "print(\"Wizard vocab size: \", len(find_vocab_tok(wizd_corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1293f43",
   "metadata": {},
   "source": [
    "We can see that the vocabulary count has actually gone up, this is because some words like \"trip\", may be counted again as a seperate token such as \"a trip\", since we retokenized. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eb7d06",
   "metadata": {},
   "source": [
    "#### Remove stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36843aab",
   "metadata": {},
   "source": [
    "We will use the `nltk` stopwords set, and remove these words from the entire corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db0a801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "u_corp_rsw = []\n",
    "w_corp_rsw = []\n",
    "\n",
    "for (i, corpus) in enumerate([user_corpus, wizd_corpus]):\n",
    "    for doc in corpus:\n",
    "        tokens = [token.text for token in doc if token.text not in stopwords]\n",
    "        if i == 0:\n",
    "            u_corp_rsw.append(tokens)\n",
    "        else:\n",
    "            w_corp_rsw.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be21c47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User vocab size  :  4062\n",
      "Wizard vocab size:  4664\n"
     ]
    }
   ],
   "source": [
    "def find_vocab_list(corpus):\n",
    "    return set([a for sl in corpus for a in sl])\n",
    "\n",
    "print(\"User vocab size  : \", len(find_vocab_list(u_corp_rsw)))\n",
    "print(\"Wizard vocab size: \", len(find_vocab_list(w_corp_rsw)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd203a2",
   "metadata": {},
   "source": [
    "To find the TF-IDF it will be easy to use the class `TfidfVectorizer` from the package `sklearn` as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba86c385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf = tfidf_vectorizer.fit_transform(user_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e42e843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features  = np.array(tfidf_vectorizer.get_feature_names())\n",
    "ix_sorter = np.argsort(tfidf.toarray()).flatten()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b547bb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['thanks', 'zone', 'exalted', 'exact', 'eww', 'ew', 'evidently',\n",
       "       'everyones', 'everybody', 'evenings'], dtype='<U28')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[ix_sorter][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc82173",
   "metadata": {},
   "source": [
    "Above we can see a NumPy array of the 10 words with the highest TF-IDF values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f95a3b",
   "metadata": {},
   "source": [
    "### Linguistic Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df1d367",
   "metadata": {},
   "source": [
    "* Design three linguistic patterns each for the following: dates, budget , origin and destination, and people (number of children + adults).\n",
    "* Retrieve the user utterance and wizard reply pairs from the `frames.json` file, and store them in a new `.json` file according to its intent.\n",
    "* Work out at least three linguistic patterns of the wizard replies for each intent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0a21fb",
   "metadata": {},
   "source": [
    "#### Linguistic Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7724ce",
   "metadata": {},
   "source": [
    "Patterns for dates:\n",
    "\n",
    "* 03/03/1998\n",
    "* 3(rd) (of) March\n",
    "* March 3(rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87d0df68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATE PATTERNS\n",
    "pat_date1 = [{\"TEXT\":{\"REGEX\":\"^(0?[1-9]|[12][0-9]|3[01])[\\/\\-](0?[1-9]|1[012])[\\/\\-]\\d{4}$\"}}]\n",
    "# Regex matches 1-2 digits, which may be followed by a 2 letter combo of \"stndrh\"\n",
    "# , for \"st\", \"nd\", \"rd\" and \"th\"\n",
    "pat_date2 = [{\"TEXT\":{\"REGEX\":\"\\d{1,2}(?:[stndrh]){2}?\"}}, {\"LOWER\":\"of\", \"OP\":\"?\"}, {\"POS\":\"PROPN\"}]\n",
    "pat_date3 = [{\"POS\":\"PROPN\"}, {\"TEXT\":{\"REGEX\":\"\\d{1,2}(?:[stndrh]){2}?\"}}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afee076c",
   "metadata": {},
   "source": [
    "Patterns for budget:\n",
    "\n",
    "* \"... \\\\$1700(.00) ...\"\n",
    "* \"... 1000 ...\" (greater than 100 if no dollar sign)\n",
    "\n",
    "Assuming budget will never be less than 100, and children never higher than 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e14fe87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUDGET PATTERNS\n",
    "pat_budg1 = [{\"TEXT\":\"$\"}, {\"POS\":\"NUM\"}]\n",
    "# Regex matches 3 digits\n",
    "pat_budg2 = [{\"TEXT\":{\"REGEX\":\"\\d{3,}\"}}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cdba69",
   "metadata": {},
   "source": [
    "Patterns for origin/destination:\n",
    "\n",
    "* \"... Perth ...\" (Just a location name)\n",
    "* \"... to/visit Adelaide ...\" (Destination)\n",
    "* \"... from/leaving Perth ...\" (Origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed2d179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGIN / DESTINATION PATTERNS\n",
    "pat_loc = [{\"ENT_TYPE\":\"GPE\"}]\n",
    "# \"at\" covers \"holiday at ...\", \"arrive at ...\", etc.\n",
    "pat_dst = [{\"LEMMA\":{\"IN\":[\"to\", \"visit\", \"at\"]}}, {\"ENT_TYPE\":\"GPE\", \"OP\":\"+\"}]\n",
    "# \"of\" covers \"out of\", etc.\n",
    "pat_ori = [{\"LEMMA\":{\"IN\":[\"from\", \"leave\", \"of\"]}}, {\"ENT_TYPE\":\"GPE\", \"OP\":\"+\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e94419",
   "metadata": {},
   "source": [
    "Patterns for number of people:\n",
    "\n",
    "* \"... 3 children ...\"\n",
    "* \"... 3 adults ...\"\n",
    "* \"... 3 people ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9134c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMBER OF PEOPLE PATTERNS\n",
    "pat_nadult = [{\"POS\":\"NUM\"}, {\"LEMMA\":\"adult\"}]\n",
    "pat_nchild = [{\"POS\":\"NUM\"}, {\"LEMMA\":\"child\"}]\n",
    "pat_npeopl = [{\"POS\":\"NUM\"}, {\"LEMMA\":\"people\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75c8e47",
   "metadata": {},
   "source": [
    "#### Retrieve and Save Utterance Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef8febc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "pair_dict = defaultdict(list)\n",
    "\n",
    "for dialogue in df.turns:\n",
    "    for i in range(0, len(dialogue), 2):\n",
    "        if dialogue[i] is None:\n",
    "            break\n",
    "            \n",
    "        acts = dialogue[i][\"labels\"][\"acts\"]\n",
    "        if i+1==len(dialogue):\n",
    "            pair = [dialogue[i][\"text\"], None]\n",
    "        else:\n",
    "            pair = [dialogue[i][\"text\"], dialogue[i+1][\"text\"]]\n",
    "        \n",
    "        if acts != []:\n",
    "            pair_dict[acts[0][\"name\"]].append(pair)\n",
    "        else:\n",
    "            pair_dict[\"no_intent\"].append(pair)\n",
    "        \n",
    "with open(\"intentdata.json\", \"w\", encoding=\"utf-8\") as fp:\n",
    "    json.dump(pair_dict, fp, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fa88af",
   "metadata": {},
   "source": [
    "#### Linguistic Patterns for Wizard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42606e49",
   "metadata": {},
   "source": [
    "For each intent, we must find linguistic patterns of the wizard's replies. \n",
    "\n",
    "From what I can see, there isn't really any general linguistic patterns that will cover the majority of the wizard's replies, so I will just try and find ones that match with as many as I can find.\n",
    "\n",
    "Also, the assignment outline is a bit confusing here, so I will be using the intents defined by the dialogue acts, since there is only 1 type of actual intent, \"book\". Because of this, if I were to write 3 linguistic patterns for each of the 13 different dialogue acts saved to the `.json` file it would take quite a long time to complete. Luckily there is a lot of crossover between the different intents/dialogue acts, so I will explicitly mention the crossover below, and use that explaination as one of the 3 linguistic patterns.\n",
    "\n",
    "Below is the list of intents saved to the `.json` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14dd36e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['inform', 'thankyou', 'negate', 'switch_frame', 'request', 'affirm', 'goodbye', 'request_compare', 'greeting', 'request_alts', 'no_intent', 'moreinfo', 'confirm'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750c7758",
   "metadata": {},
   "source": [
    "We will load the new json formatted data into corpora for each intent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a279dc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiz_intent_corpus = []\n",
    "\n",
    "for intent in pair_dict.keys():\n",
    "    temp_corpus = list(nlp.pipe([x[1] for x in pair_dict[intent] if x[1] is not None]))\n",
    "    wiz_intent_corpus.append(temp_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402a4980",
   "metadata": {},
   "source": [
    "We will also be using a dependency matcher, since it will be impossible match multiple different structures of sentence to the same questions just using a regular matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a0e243",
   "metadata": {},
   "source": [
    "\"Inform\" patterns form the vast majority of patterns, so I will define more than 3 to make up for the less than 3 that some of the othere intents have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2371d58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Budget pattern, root has children \"budget\" and \"?\"\n",
    "pat_inf_budget = [{\"RIGHT_ID\":\"root\",\n",
    "               \"RIGHT_ATTRS\":{\"DEP\":\"ROOT\"}},\n",
    "              # root has right child: budget, and \"?\"\n",
    "              {\"LEFT_ID\":\"root\",\n",
    "               \"REL_OP\":\">\",\n",
    "               \"RIGHT_ID\":\"budget\",\n",
    "               \"RIGHT_ATTRS\":{\"LEMMA\":\"budget\"}},\n",
    "              {\"LEFT_ID\":\"root\",\n",
    "               \"REL_OP\":\">\",\n",
    "               \"RIGHT_ID\":\"question\",\n",
    "               \"RIGHT_ATTRS\":{\"LEMMA\":\"?\"}}]\n",
    "pat_inf_hmp = [{\"RIGHT_ID\":\"root\",\n",
    "                      \"RIGHT_ATTRS\":{\"DEP\":\"ROOT\"}},\n",
    "                      # root has right child: budget, and \"?\"\n",
    "                     {\"LEFT_ID\":\"root\",\n",
    "                      \"REL_OP\":\">\",\n",
    "                      \"RIGHT_ID\":\"budget\",\n",
    "                      \"RIGHT_ATTRS\":{\"LEMMA\":{\"IN\":[\"children\", \"adult\", \"people\"]}}},\n",
    "                     {\"LEFT_ID\":\"root\",\n",
    "                      \"REL_OP\":\">\",\n",
    "                      \"RIGHT_ID\":\"question\",\n",
    "                      \"RIGHT_ATTRS\":{\"LEMMA\":\"?\"}}]\n",
    "# Confirm booking\n",
    "pat_inf_conf = [{\"RIGHT_ID\":\"root\",\n",
    "               \"RIGHT_ATTRS\":{\"DEP\":\"ROOT\"}},\n",
    "              # root has right child: book, and \"?\"\n",
    "              {\"LEFT_ID\":\"root\",\n",
    "               \"REL_OP\":\">\",\n",
    "               \"RIGHT_ID\":\"book\",\n",
    "               \"RIGHT_ATTRS\":{\"LEMMA\":\"book\"}},\n",
    "              {\"LEFT_ID\":\"root\",\n",
    "               \"REL_OP\":\">\",\n",
    "               \"RIGHT_ID\":\"question\",\n",
    "               \"RIGHT_ATTRS\":{\"LEMMA\":\"?\"}}]\n",
    "# Reject inquiry\n",
    "pat_inf_rej = [{\"LEMMA\":\"no\"},\n",
    "              {\"LEMMA\":\"trip\"},\n",
    "              {\"LEMMA\":\"avaliable\"}]\n",
    "\n",
    "pat_inf_dst = [{\"LEMMA\":{\"IN\":[\"to\", \"visit\", \"at\"]}}, {\"ENT_TYPE\":\"GPE\"}]\n",
    "pat_inf_ori = [{\"LEMMA\":{\"IN\":[\"from\", \"leave\", \"of\"]}}, {\"ENT_TYPE\":\"GPE\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d94b4e0",
   "metadata": {},
   "source": [
    "\"Thankyou\" patterns seem to be very simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2eaa219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_pleasure = [{\"LEMMA\":\"pleasure\"}]\n",
    "# Have a good day/trip etc.\n",
    "pat_haveagood = [{\"LEMMA\":\"have\"},\n",
    "                 {\"LEMMA\":\"a\"},\n",
    "                 {\"LEMMA\":\"good\"}]\n",
    "# You are welcome/you're welcome\n",
    "# No other situations where wizard would say welcome\n",
    "pat_welcome = [{\"LEMMA\":\"welcome\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8f1d79",
   "metadata": {},
   "source": [
    "\"Negate\" patterns are usually responses to a rejected suggestion. There is a bit of crossover here with inform as the wizard follows up with a question about different dates/budgets etc.\n",
    "\n",
    "Patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c3d6747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wizard replies sometimes with alternate booking\n",
    "pat_icanbook = [{\"LEMMA\":\"i\"},\n",
    "                {\"LEMMA\":\"can\"},\n",
    "                {\"LEMMA\":\"book\"}]\n",
    "# Suggestion\n",
    "pat_howabout = [{\"LEMMA\":\"how\"},\n",
    "                {\"LEMMA\":\"about\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1380aef2",
   "metadata": {},
   "source": [
    "\"switch_frame\" is almost exactly the  same as \"inform\", since the wizard creates a new frame the user might as well have started a new conversation. This intent covers information about budget, confirmation and rejection replies, so I will be using the same patterns as \"inform\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6729590d",
   "metadata": {},
   "source": [
    "\"request\" patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "88532dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# request for rating of hotel\n",
    "pat_stars = [{\"LEMMA\":\"star\"},\n",
    "             {\"LEMMA\":\"rating\"}]\n",
    "pat_leave = [{\"LEMMA\":\"you\"},\n",
    "             {\"LEMMA\":{\"IN\":[\"will\", \"would\"]}},\n",
    "             {\"LEMMA\":\"leave\"}]\n",
    "# The wizard wouldn's say these words unless\n",
    "# it was telling the user they were included\n",
    "pat_free = [{\"LEMMA\":\"free\"},\n",
    "            {\"LEMMA\":{\"IN\":[\"spa\", \"wifi\", \"pool\", \"parking\", \"breakfast\"]}}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa78ab9f",
   "metadata": {},
   "source": [
    "\"affirm\" patterns means the user has said yes to something. Most of the time it is the user agreeing to a booking, but sometimes they just say yes.\n",
    "\n",
    "I will make a pattern for a booked trip, most of the remaining wizard replies are covered by the \"inform\" patterns once again, since the wizard is replying to an eager customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7acc921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Booked in past tense is only used by wizard if actually booked\n",
    "pat_booked = [{\"LOWER\":\"booked\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43de943",
   "metadata": {},
   "source": [
    "\"goodbye\" pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca73145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_goodbye = [{\"LOWER\":\"goodbye\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d914c8",
   "metadata": {},
   "source": [
    "\"request_compare\" patterns:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6acd44f",
   "metadata": {},
   "source": [
    "Request compare doesn't seem to have a unique pattern either. It's a similar situation to \"switch_frame\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d73592e",
   "metadata": {},
   "source": [
    "\"greeting\" patterns are usually an actual greeting as a response, but if not it is usually covered by the \"inform\" patterns again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "561c57e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_hello = [{\"LOWER\":{\"IN\":[\"hello\", \"hi\", \"hey\"]}}]\n",
    "# how can i help/what can i do\n",
    "pat_cani = [{\"LOWER\":{\"IN\":[\"what\", \"how\"]}},\n",
    "            {\"LOWER\":\"can\"},\n",
    "            {\"LOWER\":\"i\"},\n",
    "            {\"LOWER\":{\"IN\":[\"do\", \"help\"]}}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50faccc",
   "metadata": {},
   "source": [
    "\"request_alts\" patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d04b22d",
   "metadata": {},
   "source": [
    "This is basically the same patterns as \"inform\", since the alternative options will be described in the same way as the initial options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606dc3ab",
   "metadata": {},
   "source": [
    "\"no_intent\" patterns are mostly covered by inform patterns, since it seems like they mostly relate to confirming a booking. Some replies are apologies from the wizard, but I can't think of a way to distinguish the apologies here from the ones in \"request\", where the wizard couldn't find any results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dafcdaa",
   "metadata": {},
   "source": [
    "\"moreinfo\" is fully covered by the \"inform\" and \"request\" patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6041af",
   "metadata": {},
   "source": [
    "\"confirm\" pattern is simply the user trying to confirm something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3faffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_yes = [{\"LOWER\":{\"IN\":[\"yes\", \"correct\"]}}]\n",
    "pat_no  = [{\"LOWER\":\"no\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36a4644",
   "metadata": {},
   "source": [
    "### Chatbot Implementation and Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e342c6b7",
   "metadata": {},
   "source": [
    "* Design the intents that your bot can handle\n",
    "* Consider the use of a random list of answers for each intent\n",
    "* Use the designed linguistic patterns to parse user input and map to the relevant intent\n",
    "* Reply with an answer generated from the linguistic patterns extracted from the wizards.\n",
    "* Deploy on Telegram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50e201",
   "metadata": {},
   "source": [
    "Here, I will redefine the term \"intent\".\n",
    "\n",
    "Previous to this section, \"intent\" was defined as the dialogue acts (\"inform\", \"request\", etc.), but upon coming to this point in this assignment, I can see that I should've had the defined as the attributes required to make a booking (\"date\", \"destination\", etc.). From this point, I will use this definition for intent, and will create new linguistic patterns as needed in the upcoming parts. However, within the old intents above there are a few linguistic patterns that can be used for the new definitions. I will discuss in the Markdown anything that needs clarification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318c59b1",
   "metadata": {},
   "source": [
    "There is no indication in the outline that the bot has to be able to hold a conversation, or actually be a usable chatbot for the purpose of hotel bookings. As far as I am aware, all it needs to do is parse a user input, determine the intent, and respond in a similar way to the wizard in the `Frames` dataset. \n",
    "\n",
    "The bot that I have created is very simple, and simply responds to any user input. It is able to handle the intents date, location, number of people and budget (only one at a time), and then respond in the same way the wizard would if it were accepting the input as valid, and available as a hotel option. The bot can only handle one intent at a time, however this would be rather easy to change. Simply parse the user input for any matching patterns, get the intent from the matched patterns, and reply/save the information and continue the conversation. This bot is unable to remember anything, and there is no coversation flow, that can be implemented using the `ConversationHandler` class. I simply did not have enough time to implement these things."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec938987",
   "metadata": {},
   "source": [
    "The name of the chatbot is `HotelBot` and the username `the_bot_that_books_hotels_bot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ada10e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is_bot': True, 'first_name': 'HotelBot', 'id': 1960188621, 'username': 'the_bot_that_books_hotels_bot', 'supports_inline_queries': False, 'can_join_groups': True, 'can_read_all_group_messages': False}\n"
     ]
    }
   ],
   "source": [
    "import telegram\n",
    "bot_tok = \"1960188621:AAE7UX826swsxuwy_aV_R5dJqxrl7wLbI4A\"\n",
    "bot = telegram.Bot(token=bot_tok)\n",
    "print(bot.get_me())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4951d9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Detect to or from dates\n",
    "patterns_todate = []\n",
    "for pat in [pat_date1, pat_date2, pat_date3]:\n",
    "    patterns_todate.append([{\"LEMMA\":{\"IN\":[\"until\", \"to\"]}}, {\"LEMMA\":\"the\", \"OP\":\"?\"}] + pat)\n",
    "\n",
    "matcher.add(\"date_to\", patterns_todate)\n",
    "\n",
    "patterns_fromdate = []\n",
    "for pat in [pat_date1, pat_date2, pat_date3]:\n",
    "    patterns_fromdate.append([{\"LEMMA\":\"from\"}, {\"LEMMA\":\"the\", \"OP\":\"?\"}] + pat)\n",
    "\n",
    "matcher.add(\"date_from\", patterns_fromdate)    \n",
    "\n",
    "# Detect GPE for origin and destination\n",
    "matcher.add(\"loc_dest\", [pat_dst], greedy=\"LONGEST\")\n",
    "matcher.add(\"loc_orig\", [pat_ori], greedy=\"LONGEST\")\n",
    "\n",
    "# Detect number of people\n",
    "matcher.add(\"num_adults\", [pat_nadult]) \n",
    "matcher.add(\"num_children\", [pat_nchild])\n",
    "matcher.add(\"num_people\", [pat_npeopl])\n",
    "\n",
    "# Detect budget\n",
    "matcher.add(\"budget\", [pat_budg1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a8f208f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from telegram.ext import Updater, MessageHandler, Filters\n",
    "import random\n",
    "\n",
    "def extract_intent(doc):\n",
    "    # Find the intent: date, location, budget or people\n",
    "    # Can only handle one intent per utterance\n",
    "    matches = matcher(doc)\n",
    "    user_intent = \"\"\n",
    "    intent_info = {}\n",
    "    for match_id, start, end in matches:\n",
    "        match_name = nlp.vocab.strings[match_id]\n",
    "        user_intent = match_name.split(\"_\")[0]\n",
    "        \n",
    "        intent_info[match_name] = doc[start:end].text.lower()\n",
    "        \n",
    "    return user_intent, intent_info\n",
    "\n",
    "def utterance(update, context):\n",
    "    msg = update.message.text\n",
    "    doc = nlp(msg)\n",
    "    \n",
    "    intent, info = extract_intent(doc)\n",
    "    \n",
    "    update.message.reply_text(intent)\n",
    "    update.message.reply_text(info)\n",
    "    \n",
    "    # please, dont look any further\n",
    "    if intent == \"date\":\n",
    "        if \"date_to\" in info.keys():\n",
    "            if \"date_from\" in info.keys():\n",
    "                if random.randint(0, 1):\n",
    "                    update.message.reply_text(f\"Great! I have a few packages available for these dates. What's your budget?\")\n",
    "                else:\n",
    "                    update.message.reply_text(f\"Unfortunately I have nothing available for these dates. Can you leave at another date?\")\n",
    "            else:\n",
    "                update.message.reply_text(\"And what date would you like to arrive?\")\n",
    "        if \"date_from\" in info.keys():\n",
    "            if \"date_to\" not in info.keys():\n",
    "                update.message.reply_text(\"What date will you be heading home?\")\n",
    "        \n",
    "    if intent == \"loc\":\n",
    "        if \"loc_dest\" in info.keys():\n",
    "            if \"loc_orig\" in info.keys():\n",
    "                update.message.reply_text(f\"We have a 6 day trip available, would you like me to book now?\")\n",
    "            else:\n",
    "                update.message.reply_text(\"Please specify where you will leave from\")\n",
    "        if \"loc_orig\" in info.keys():\n",
    "            if \"loc_dest\" not in info.keys():\n",
    "                update.message.reply_text(\"Where do you want to go?\")\n",
    "        \n",
    "    if intent == \"budget\":\n",
    "        if \"budget\" in info.keys():\n",
    "            update.message.reply_text(f\"We have a couple trips available for less than {info['budget']}\")\n",
    "        \n",
    "    if intent == \"num\":\n",
    "        reply = \"Here are bookings for \"\n",
    "        if \"num_people\" in info.keys():\n",
    "            reply += str(info[\"num_people\"])\n",
    "        if \"num_adults\" in info.keys():\n",
    "            reply += str(info[\"num_adults\"])\n",
    "        if \"num_children\" in info.keys():\n",
    "            reply += \"and \" + str(info[\"num_children\"])\n",
    "        \n",
    "        update.message.reply_text(reply)\n",
    "        \n",
    "    if not intent:\n",
    "        update.message.reply_text(\"Unfortunately I could not understand your intent.\")\n",
    "        \n",
    "        \n",
    "# Telegram API instructions\n",
    "updater = Updater(bot_tok, use_context=True)\n",
    "updater.dispatcher.add_handler(MessageHandler(Filters.text, utterance))\n",
    "updater.start_polling()\n",
    "updater.idle()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dedba58",
   "metadata": {},
   "source": [
    "### Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9f989",
   "metadata": {},
   "source": [
    "Grammar induction in the `Frames` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fdb63f",
   "metadata": {},
   "source": [
    "Grammar induction is a machine learning technique of learning formal grammar, or how to form valid words in a language, from a set of text. The frames dataset obviously has a lot of text in it, since there's around 6500 user turns. The `Frames` dataset should be a good source of text to train a finite-state machines, neural network, or some other generative machine learning model. Since the wizard was instructed to act like an AI or misinterpret the user sometimes, the stucture of the wizards sentences, or the relationship between the users message, and the wizards reply may be strange. However, I don't think this is a problem, for the most part the dataset consists of proper sentences, and correctly spelt words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
