{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37ef5acf",
   "metadata": {},
   "source": [
    "# Project 2\n",
    "Kai Bagley - 21984315\n",
    "\n",
    "* Data Exploration\n",
    "* Preprocessing, and\n",
    "* Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc31947",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc25b742",
   "metadata": {},
   "source": [
    "I will be trying two different language models on two NLP tasks: Document Classification and Entity Recognition.\n",
    "\n",
    "This will be done on the US Mining Safety Logs data set, which records the injuries of employees working in the mining industry. This dataset includes the structured fields (and more):\n",
    "\n",
    "* `NATURE_INJURY`: Nature of the injury, eg. `SPRAIN`.\n",
    "* `INJ_BODY_PART`: Injured body part, eg. `HEAD`.\n",
    "* `ACTIVITY`: Activity that was being done at the time of injury, eg. `HAND_TOOLS`.\n",
    "* `INJURY_SOURCE`: Source of injury, eg. `AXE`.\n",
    "\n",
    "There is also a `NARRATIVE` field that contains unstructured short texts describing the incident in detail. This ifield contains valuable information which could help improve workplace safety.\n",
    "\n",
    "I will be attempting to retrieve useful information from the narratives using document classification and entity recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d1da10",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff145dac",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf462695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a792eb",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a0924ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEGREE_INJURY_CD</th>\n",
       "      <th>DEGREE_INJURY</th>\n",
       "      <th>ACTIVITY_CD</th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>INJURY_SOURCE_CD</th>\n",
       "      <th>INJURY_SOURCE</th>\n",
       "      <th>NATURE_INJURY_CD</th>\n",
       "      <th>NATURE_INJURY</th>\n",
       "      <th>INJ_BODY_PART_CD</th>\n",
       "      <th>INJ_BODY_PART</th>\n",
       "      <th>NARRATIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>DAYS RESTRICTED ACTIVITY ONLY</td>\n",
       "      <td>28</td>\n",
       "      <td>HANDLING SUPPLIES/MATERIALS</td>\n",
       "      <td>76</td>\n",
       "      <td>SURFACE MINING MACHINES</td>\n",
       "      <td>160</td>\n",
       "      <td>CONTUSN,BRUISE,INTAC SKIN</td>\n",
       "      <td>700</td>\n",
       "      <td>MULTIPLE PARTS (MORE THAN ONE MAJOR)</td>\n",
       "      <td>Employee was cleaning up at the Primary Crushe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>NO DYS AWY FRM WRK,NO RSTR ACT</td>\n",
       "      <td>30</td>\n",
       "      <td>HAND TOOLS (NOT POWERED)</td>\n",
       "      <td>46</td>\n",
       "      <td>AXE,HAMMER,SLEDGE</td>\n",
       "      <td>180</td>\n",
       "      <td>CUT,LACER,PUNCT-OPN WOUND</td>\n",
       "      <td>100</td>\n",
       "      <td>HEAD,NEC</td>\n",
       "      <td>Handle of sledgehammer broke and head of hamme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>DAYS AWAY FROM WORK ONLY</td>\n",
       "      <td>13</td>\n",
       "      <td>CLIMB SCAFFOLDS/LADDERS/PLATFORMS</td>\n",
       "      <td>117</td>\n",
       "      <td>GROUND</td>\n",
       "      <td>330</td>\n",
       "      <td>SPRAIN,STRAIN RUPT DISC</td>\n",
       "      <td>520</td>\n",
       "      <td>ANKLE</td>\n",
       "      <td>EMPLOYEE WAS CLIMBING DOWN A LADDER AND WHEN H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>DAYS RESTRICTED ACTIVITY ONLY</td>\n",
       "      <td>28</td>\n",
       "      <td>HANDLING SUPPLIES/MATERIALS</td>\n",
       "      <td>4</td>\n",
       "      <td>BAGS</td>\n",
       "      <td>330</td>\n",
       "      <td>SPRAIN,STRAIN RUPT DISC</td>\n",
       "      <td>420</td>\n",
       "      <td>BACK (MUSCLES/SPINE/S-CORD/TAILBONE)</td>\n",
       "      <td>HE PULLED A BACK MUSCLE WHILE STACKING BAGS OF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>DAYS RESTRICTED ACTIVITY ONLY</td>\n",
       "      <td>96</td>\n",
       "      <td>WORKING WITH CHEMICALS</td>\n",
       "      <td>21</td>\n",
       "      <td>ACIDS,ALKALI,WET CEMENT</td>\n",
       "      <td>130</td>\n",
       "      <td>BURN,CHEMICL-FUME,COMPOUN</td>\n",
       "      <td>330</td>\n",
       "      <td>HAND (NOT WRIST OR FINGERS)</td>\n",
       "      <td>EE hands began to break out in a rash after he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DEGREE_INJURY_CD                   DEGREE_INJURY ACTIVITY_CD  \\\n",
       "0                5   DAYS RESTRICTED ACTIVITY ONLY          28   \n",
       "1                6  NO DYS AWY FRM WRK,NO RSTR ACT          30   \n",
       "2                3        DAYS AWAY FROM WORK ONLY          13   \n",
       "3                5   DAYS RESTRICTED ACTIVITY ONLY          28   \n",
       "4                5   DAYS RESTRICTED ACTIVITY ONLY          96   \n",
       "\n",
       "                            ACTIVITY INJURY_SOURCE_CD  \\\n",
       "0        HANDLING SUPPLIES/MATERIALS               76   \n",
       "1           HAND TOOLS (NOT POWERED)               46   \n",
       "2  CLIMB SCAFFOLDS/LADDERS/PLATFORMS              117   \n",
       "3        HANDLING SUPPLIES/MATERIALS                4   \n",
       "4             WORKING WITH CHEMICALS               21   \n",
       "\n",
       "             INJURY_SOURCE NATURE_INJURY_CD              NATURE_INJURY  \\\n",
       "0  SURFACE MINING MACHINES              160  CONTUSN,BRUISE,INTAC SKIN   \n",
       "1        AXE,HAMMER,SLEDGE              180  CUT,LACER,PUNCT-OPN WOUND   \n",
       "2                   GROUND              330    SPRAIN,STRAIN RUPT DISC   \n",
       "3                     BAGS              330    SPRAIN,STRAIN RUPT DISC   \n",
       "4  ACIDS,ALKALI,WET CEMENT              130  BURN,CHEMICL-FUME,COMPOUN   \n",
       "\n",
       "  INJ_BODY_PART_CD                         INJ_BODY_PART  \\\n",
       "0              700  MULTIPLE PARTS (MORE THAN ONE MAJOR)   \n",
       "1              100                              HEAD,NEC   \n",
       "2              520                                 ANKLE   \n",
       "3              420  BACK (MUSCLES/SPINE/S-CORD/TAILBONE)   \n",
       "4              330           HAND (NOT WRIST OR FINGERS)   \n",
       "\n",
       "                                           NARRATIVE  \n",
       "0  Employee was cleaning up at the Primary Crushe...  \n",
       "1  Handle of sledgehammer broke and head of hamme...  \n",
       "2  EMPLOYEE WAS CLIMBING DOWN A LADDER AND WHEN H...  \n",
       "3  HE PULLED A BACK MUSCLE WHILE STACKING BAGS OF...  \n",
       "4  EE hands began to break out in a rash after he...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"DEGREE_INJURY\", \n",
    "        \"DEGREE_INJURY_CD\",\n",
    "        \"NATURE_INJURY\",\n",
    "        \"NATURE_INJURY_CD\",\n",
    "        \"INJ_BODY_PART\",\n",
    "        \"INJ_BODY_PART_CD\",\n",
    "        \"ACTIVITY\",\n",
    "        \"ACTIVITY_CD\",\n",
    "        \"INJURY_SOURCE\",\n",
    "        \"INJURY_SOURCE_CD\",\n",
    "        \"NARRATIVE\"]\n",
    "\n",
    "df = pd.read_csv(\"./data/us_data_2000.csv\", usecols=cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499ac9d9",
   "metadata": {},
   "source": [
    "#### Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2417d0f",
   "metadata": {},
   "source": [
    "This step requires a 80/20 Train/Test split, but also requires a validation set. The way I interpret this requirement is to do a 80/20 split to give `train` and `test` sets, and then I will take another 20% split from the `train` set to give `train` and `valid`. `train` will be overwritten such that the split is actually 60/20/20 train/test/valid.\n",
    "\n",
    "Before we do any of that, I will first drop any `na` occurences, and any with a class label `?`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81345438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"NARRATIVE\"].notnull()]\n",
    "\n",
    "df = df.drop(df[df[\"DEGREE_INJURY_CD\"]==\"?\"].index)\n",
    "df = df.drop(df[df[\"ACTIVITY_CD\"]==\"?\"].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3682de69",
   "metadata": {},
   "source": [
    "Since task 1 is a binary classification problem, the first class will contain all incidents where the accident was known to impact the activity of the person (eg. `FATALITY`, `DAYS_RESTRICTED_ACTIVITY_ONLY`, etc), and the second class will be everything else (unknown impact `ACCIDENT_ONLY` etc. included). Task 1 only requires `NARRATIVE`, `DEGREE_INJURY` and `DEGREE_INJURY_CD` only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86d435f",
   "metadata": {},
   "source": [
    "#### Task 1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19f4127b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEGREE_INJURY_CD</th>\n",
       "      <th>DEGREE_INJURY</th>\n",
       "      <th>NARRATIVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DAYS RESTRICTED ACTIVITY ONLY</td>\n",
       "      <td>Employee was cleaning up at the Primary Crushe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NO DYS AWY FRM WRK,NO RSTR ACT</td>\n",
       "      <td>Handle of sledgehammer broke and head of hamme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>DAYS AWAY FROM WORK ONLY</td>\n",
       "      <td>EMPLOYEE WAS CLIMBING DOWN A LADDER AND WHEN H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>DAYS RESTRICTED ACTIVITY ONLY</td>\n",
       "      <td>HE PULLED A BACK MUSCLE WHILE STACKING BAGS OF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>DAYS RESTRICTED ACTIVITY ONLY</td>\n",
       "      <td>EE hands began to break out in a rash after he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DEGREE_INJURY_CD                   DEGREE_INJURY  \\\n",
       "0                 0   DAYS RESTRICTED ACTIVITY ONLY   \n",
       "1                 1  NO DYS AWY FRM WRK,NO RSTR ACT   \n",
       "2                 0        DAYS AWAY FROM WORK ONLY   \n",
       "3                 0   DAYS RESTRICTED ACTIVITY ONLY   \n",
       "4                 0   DAYS RESTRICTED ACTIVITY ONLY   \n",
       "\n",
       "                                           NARRATIVE  \n",
       "0  Employee was cleaning up at the Primary Crushe...  \n",
       "1  Handle of sledgehammer broke and head of hamme...  \n",
       "2  EMPLOYEE WAS CLIMBING DOWN A LADDER AND WHEN H...  \n",
       "3  HE PULLED A BACK MUSCLE WHILE STACKING BAGS OF...  \n",
       "4  EE hands began to break out in a rash after he...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get rows where injury code = [1, 2, 3, 4, 5] (described above)\n",
    "cls0 = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "cls1 = [str(x) for x in range(13) if x not in cls0]\n",
    "\n",
    "binary_class_dict = {1:\"Serious Injury\", 0:\"Non-Serious Injury\"}\n",
    "\n",
    "task1_df = df[[\"DEGREE_INJURY_CD\", \"DEGREE_INJURY\", \"NARRATIVE\"]].copy()\n",
    "task1_df[\"DEGREE_INJURY_CD\"].replace(cls0, 0, inplace=True)\n",
    "task1_df[\"DEGREE_INJURY_CD\"].replace(cls1, 1, inplace=True)\n",
    "\n",
    "# Train, test and valid sets\n",
    "train1, test1  = train_test_split(task1_df, train_size=0.8)\n",
    "train1, valid1 = train_test_split(train1, train_size=0.8)\n",
    "\n",
    "# Write dataframes to CSV\n",
    "train1.to_csv(\"./data/task1/train.csv\")\n",
    "test1.to_csv(\"./data/task1/test.csv\")\n",
    "valid1.to_csv(\"./data/task1/valid.csv\")\n",
    "\n",
    "task1_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec2494",
   "metadata": {},
   "source": [
    "#### Task 2 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a241e83",
   "metadata": {},
   "source": [
    "Task 2 requires multiclass classification. Below are all the relevant columns, but for the classification I will be using `ACTIVITY` as the class labels (In particular, the code `_CD` values):\n",
    "\n",
    "* `NATURE_INJURY`\n",
    "* `INJ_BODY_PART`\n",
    "* `ACTIVITY`\n",
    "* `INJURY_SOURCE`\n",
    "* `NARRATIVE`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae7721d",
   "metadata": {},
   "source": [
    "Since there are classes with very few occurences, sometimes the vectorizer will not be able to add every class to the vocabulary, so we can avoid this by removing observations with very infrequent classes, and then using `stratify` in the `train_test_split` call, which will retain the class proportions when returning the splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aab2346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>ACTIVITY_CD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>EE OPENED DOOR TO GET OUT OF TRUCK WHICH WAS O...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>EE assisting in mill liner job. Liner on dolly...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>Emp. lifted tool box out of truck and felt pai...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>Employee slipped off the last rung of a ladder...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>EE STATED HE PUSHED DOWN WITH A BAR ON A KILN ...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>Employee was dismounting from skid steer.  He ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>EE WAS COMING TO WORK &amp; STEPPED OFF SIDEWALK H...</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>During the raising process the workdeck winche...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>EMPLOYEE STEPPED OUT OF BUCKET TRUCK AND TWIST...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>The injured EE was removing decorative rocks i...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              NARRATIVE ACTIVITY_CD\n",
       "471   EE OPENED DOOR TO GET OUT OF TRUCK WHICH WAS O...          23\n",
       "152   EE assisting in mill liner job. Liner on dolly...          28\n",
       "1674  Emp. lifted tool box out of truck and felt pai...          28\n",
       "412   Employee slipped off the last rung of a ladder...          41\n",
       "1447  EE STATED HE PUSHED DOWN WITH A BAR ON A KILN ...          30\n",
       "...                                                 ...         ...\n",
       "568   Employee was dismounting from skid steer.  He ...          23\n",
       "1459  EE WAS COMING TO WORK & STEPPED OFF SIDEWALK H...          92\n",
       "363   During the raising process the workdeck winche...          23\n",
       "1828  EMPLOYEE STEPPED OUT OF BUCKET TRUCK AND TWIST...          23\n",
       "1343  The injured EE was removing decorative rocks i...          26\n",
       "\n",
       "[231 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task2cols = [\"ACTIVITY\", \"ACTIVITY_CD\", \"NARRATIVE\"]\n",
    "task2_df = df[task2cols]\n",
    "\n",
    "# Drop underrepresented classes, threshold = 20\n",
    "task2_df = task2_df.groupby(\"ACTIVITY_CD\").filter(lambda x: len(x)>20)\n",
    "\n",
    "x_a, x_b, y_a, y_b = train_test_split(task2_df[\"NARRATIVE\"], task2_df[\"ACTIVITY_CD\"], train_size=0.8, stratify=task2_df[\"ACTIVITY_CD\"])\n",
    "test2 = pd.concat([x_b, y_b], axis=1)\n",
    "x_a, x_b, y_a, y_b = train_test_split(x_a, y_a, train_size=0.8, stratify=y_a)\n",
    "train2 = pd.concat([x_a, y_a], axis=1)\n",
    "valid2 = pd.concat([x_b, y_b], axis=1)\n",
    "\n",
    "# Write dataframes to CSV\n",
    "train2.to_csv(\"./data/task2/train.csv\")\n",
    "test2.to_csv(\"./data/task2/test.csv\")\n",
    "valid2.to_csv(\"./data/task2/valid.csv\")\n",
    "\n",
    "valid2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd01a79f",
   "metadata": {},
   "source": [
    "#### Visualising the class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea493cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inj_counts = df[\"DEGREE_INJURY\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2fddbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax = inj_counts.plot(kind=\"barh\")\n",
    "ax.set_title(\"Injury Degree Hist\")\n",
    "ax.set_ylabel(\"Injury Degree\")\n",
    "ax.xaxis.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40955a19",
   "metadata": {},
   "source": [
    "#### Visualise the entity distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f93dced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cffc454",
   "metadata": {},
   "source": [
    "This cell may take a very long time if run on a large dataset, so we will only use up to the first 2000 observations as a sample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdc5daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_data = df.iloc[:2000]\n",
    "ne_narr  = list(nlp.pipe(ner_data[\"NARRATIVE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec700d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ne = []\n",
    "for doc in ne_narr:\n",
    "    ne.append([(x.text, x.label_) for x in doc.ents])\n",
    "ne_counts = pd.DataFrame([a for b in ne for a in b])[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "064c9333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax = ne_counts.plot(kind=\"barh\")\n",
    "ax.set_title(\"Named Entity Distribution\")\n",
    "ax.set_ylabel(\"Named Entity\")\n",
    "ax.xaxis.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a37e2c",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571dd2a0",
   "metadata": {},
   "source": [
    "Create a dataset for each task, and two Vectorizers (one for one-hot, and another pre-trained embedding). Follow the pre-processing steps:\n",
    "\n",
    "* Tokenize\n",
    "* Lemmatize, compare with stemming\n",
    "* Remove stop words (rank according to tf-idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7f6476",
   "metadata": {},
   "source": [
    "Tokenization will be done automatically in the `Vocabulary` class, in the `add_token`/`add_tokens` methods.\n",
    "\n",
    "I will define a function below for finding stopwords, by using the `sklearn` class `TfidfVectorizer` on the narratives.\n",
    "\n",
    "Both the removal of stopwords and lemmatization will occur in the `NarrativeDataset` class, in method `load_dataset_make_vectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd247050",
   "metadata": {},
   "source": [
    "#### Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dcdac0",
   "metadata": {},
   "source": [
    "Pretrained embeddings will only be used in conjunction with the vectorizer class `PEVectorizer`, as they will not be usable with a vectorizer that encodes into one-hot vectors. These embeddings will be imported using glove, from the file `glove.6B.100d.txt`, a 100-dimensional, 6-billion token file of word vectors. These are learned from a dump of Wikipedia in 2014, and the Gigaword 5 archive.\n",
    "\n",
    "For the most part, the embeddings are handled within the classifier classes themselves, but for Task 1 it was a bit different. For this task, the MLP doesn't use any embedding, it just takes the one-hot vectorized words, but the CNN does take embeddings. It can take pretrained or do the embeddings itself depending on the argument in the `args` namespace: `use_glove`. If `True`, then it uses the above GloVe embeddings, if `False` it will use it's own embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d1effb",
   "metadata": {},
   "source": [
    "#### Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7b22a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform(df[\"NARRATIVE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da025752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'was', 'and', 'his', 'on', 'to', 'he', 'employee', 'of', 'in', 'ee', 'when', 'left', 'back', 'right', 'while', 'hand', 'fell', 'from', 'slipped', 'finger', 'with', 'rock', 'off', 'it', 'causing', 'piece', 'up', 'pain', 'out', 'felt', 'truck', 'knee', 'that', 'him', 'into', 'at', 'down', 'belt', 'work', 'hit', 'cut', 'struck', 'for', 'between', 'lower', 'as', 'not', 'foot', 'had']\n"
     ]
    }
   ],
   "source": [
    "features  = np.array(tfidf_vectorizer.get_feature_names())\n",
    "sums = tfidf.sum(axis=0)\n",
    "\n",
    "data = []\n",
    "for col, feature in enumerate(features):\n",
    "    data.append((feature, sums[0, col]))\n",
    "    \n",
    "ranking = pd.DataFrame(data, columns=[\"features\", \"rank\"])\n",
    "\n",
    "stopwords = list(ranking.sort_values('rank', ascending=False)[:50][\"features\"])\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196808ce",
   "metadata": {},
   "source": [
    "## Task 1: Binary Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614253ed",
   "metadata": {},
   "source": [
    "#### Define `Task1Dataset` class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd6cfa9",
   "metadata": {},
   "source": [
    "This class was mostly taken from the lab notes, with a few changes made to suit the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "871ba636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "class Task1Dataset(Dataset):\n",
    "    def __init__(self, train_df, test_df, valid_df, vectorizer):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            train_df (pandas.DataFrame): Training dataset\n",
    "            test_df (pandas.DataFrame): Test dataset\n",
    "            valid_df (pandas.DataFrame): Validation dataset\n",
    "            vectorizer (object): Vectorizer created from dataset\n",
    "        \"\"\"\n",
    "        self._vectorizer = vectorizer\n",
    "        \n",
    "        self.train_df = train_df\n",
    "        self.train_size = len(self.train_df)\n",
    "        \n",
    "        self.test_df = test_df\n",
    "        self.test_size = len(self.test_df)\n",
    "        \n",
    "        self.valid_df = valid_df\n",
    "        self.valid_size = len(self.valid_df)\n",
    "        \n",
    "        self.df = train_df.append(test_df).append(valid_df)\n",
    "        \n",
    "        # +2 for end and begin tokens\n",
    "        measure_len = lambda sent: len(sent.split(\" \"))\n",
    "        self._max_seq_length = max(map(measure_len, self.df[\"NARRATIVE\"])) + 2\n",
    "        \n",
    "        self._lookup_dict = {\"train\": (self.train_df, self.train_size),\n",
    "                             \"test\": (self.test_df, self.test_size),\n",
    "                             \"valid\": (self.valid_df, self.valid_size)}\n",
    "        self.set_split(\"train\")\n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset_make_vectorizer(cls, folder_path, vectorizer):\n",
    "        \"\"\"Load dataset and make a new vectorizer from it\n",
    "        Args:\n",
    "            csv (str): Path to folder containing data CSVs\n",
    "            vectorizer (object): One of the two Vectorizer classes,\n",
    "                OHVectorizer for one hot, or \n",
    "                PEVectorizer for use with pretrained embeddings\n",
    "        Returns:\n",
    "            Instance of Task1Dataset\n",
    "        \"\"\"\n",
    "        train_df = pd.read_csv(folder_path + \"train.csv\")\n",
    "        test_df = pd.read_csv(folder_path + \"test.csv\")\n",
    "        valid_df = pd.read_csv(folder_path + \"valid.csv\")\n",
    "        \n",
    "        # Remove stopwords\n",
    "        for x in [train_df, test_df, valid_df]:\n",
    "            x[\"NARRATIVE\"] = x[\"NARRATIVE\"].str.lower().apply(lambda x:\" \".join([w for w in x.split(\" \") if w not in stopwords]))\n",
    "        \n",
    "        # Lemmatize\n",
    "        for x in [train_df, test_df, valid_df]:\n",
    "            x[\"NARRATIVE\"] = x[\"NARRATIVE\"].apply(lambda x:\" \".join([lemmatizer.lemmatize(w) for w in x.split(\" \")]))\n",
    "        \n",
    "        return cls(train_df, test_df, valid_df, vectorizer.from_dataframe(train_df))\n",
    "    \n",
    "    def get_vectorizer(self):\n",
    "        \"\"\"Returns vectorizer\"\"\"\n",
    "        return self._vectorizer\n",
    "    \n",
    "    def set_split(self, split=\"train\"):\n",
    "        \"\"\"Selects the chosen dataset\n",
    "        Args: \n",
    "            split (str): Select \"train\", \"test\", \"valid\"\n",
    "        \"\"\"\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Allow indexing of dataset\n",
    "        Args:\n",
    "            index (int): Index of desired datapoint\n",
    "        Returns:\n",
    "            Dictionary with datapoint's features and labels\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "\n",
    "        narr_vector = self._vectorizer.vectorize(row[\"NARRATIVE\"], self._max_seq_length)\n",
    "        injurycd_idx = self._vectorizer.injury_codes.lookup_token(row[\"DEGREE_INJURY_CD\"])\n",
    "        return {\"features\":narr_vector,\n",
    "                \"labels\":injurycd_idx}\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"Return number of batches in dataset from a given batch size\n",
    "        Args:\n",
    "            batch_size (int)\n",
    "        Returns:\n",
    "            Number of batches in the dataset\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e85f32",
   "metadata": {},
   "source": [
    "#### Create a dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a96cf0",
   "metadata": {},
   "source": [
    "Groups the vectorized datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4f4b9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "def gen_batches(dataset, batch_size, shuffle=True, drop_last=True, device=\"cpu\"):\n",
    "    \"\"\"Generator function, wraps PyTorch DataLoader and ensures \n",
    "    each tensor is in the right device\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)\n",
    "    \n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d157d75e",
   "metadata": {},
   "source": [
    "#### Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e76b117",
   "metadata": {},
   "source": [
    "Base vocabulary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0faf15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Processes text and extracts vocab\"\"\"\n",
    "    def __init__(self, tok_to_idx=None):\n",
    "        \"\"\"Args:\n",
    "            tok_to_idx (dict): Dictionary that maps tokens to indices\n",
    "        \"\"\"\n",
    "        if tok_to_idx is None:\n",
    "            tok_to_idx = {}\n",
    "        self._tok_to_idx = tok_to_idx\n",
    "        self._idx_to_tok = {idx:token for token, idx in self._tok_to_idx.items()}\n",
    "\n",
    "    def to_serializable(self):\n",
    "        return {\"tok_to_idx\":self._tok_to_idx}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, dictionary):\n",
    "        \"\"\"Creates a Vocabulary from a serialized dict\"\"\"\n",
    "        return cls(**dictionary)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        \"\"\"Update Vocabulary with a new token\n",
    "\n",
    "        Args:\n",
    "            token (str): The token to add to the Vocabulary\n",
    "        Returns:\n",
    "            index (int): Integer index corresponding to the token \n",
    "        \"\"\"\n",
    "\n",
    "        if token in self._tok_to_idx:\n",
    "            index = self._tok_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._tok_to_idx)\n",
    "            self._tok_to_idx[token] = index\n",
    "            self._idx_to_tok[index] = token\n",
    "        return index\n",
    "\n",
    "    def add_tokens(self, tokens):\n",
    "        \"\"\"Updates Vocabulary with multiple tokens\n",
    "\n",
    "        Args: \n",
    "            tokens (list): List of tokens (str)s\n",
    "        Returns:\n",
    "            indices (list): List of indices (int)s\n",
    "        \"\"\"\n",
    "\n",
    "        return [self.add_token(token) for token in tokens]\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Returns index of a token\n",
    "\n",
    "        Args:\n",
    "            token (str): Token to to find index for\n",
    "        Returns:\n",
    "            index (int): The index of the token\n",
    "        \"\"\"\n",
    "        return self._tok_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Returns token at index\n",
    "\n",
    "        Args:\n",
    "            index (int): Index to search for\n",
    "        Returns:\n",
    "            token (str): Associated token\n",
    "        \"\"\"\n",
    "\n",
    "        if index not in self._idx_to_tok:\n",
    "            raise KeyError(f\"Index ({index}) is not in the Vocabulary\")\n",
    "        return self._idx_to_tok[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<Vocabulary(size={len(self)})>\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._tok_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5876710f",
   "metadata": {},
   "source": [
    "#### Sequence Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53319fc",
   "metadata": {},
   "source": [
    "Class for the narrative sentences as sequences of words, beginning and ending with special tokens. The class inherits from the `Vocabulary` class above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c7cf08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below Vocabulary object is from lab 9\n",
    "\n",
    "class SequenceVocabulary(Vocabulary):\n",
    "    \"\"\"Processes text and extracts vocab, for sequences\"\"\"\n",
    "    def __init__(self, add_unk=True, tok_to_idx=None, unk_token=\"<UNK>\", mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\", end_seq_token=\"<END>\"):\n",
    "        \"\"\"Args:\n",
    "            tok_to_idx (dict): Dictionary that maps tokens to indices\n",
    "            unk_token (str): The UNK token that will be added to the Vocabulary\n",
    "            mask_token (str): Used as padding for embedding\n",
    "            begin_seq_token (str): Start of a sequence\n",
    "            end_seq_token (str): End of a sequence\n",
    "        \"\"\"\n",
    "        super(SequenceVocabulary, self).__init__(tok_to_idx)\n",
    "        \n",
    "        self._add_unk = add_unk\n",
    "        self._unk_token = unk_token\n",
    "        self._mask_token = mask_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "        \n",
    "        self.unk_index = self.add_token(self._unk_token)\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
    "        \n",
    "    def to_serializable(self):\n",
    "        return {\"tok_to_idx\":self._tok_to_idx,\n",
    "                \"unk_token\":self._unk_token,\n",
    "                \"mask_token\":self._mask_token,\n",
    "                \"begin_seq_token\":self._begin_seq_token,\n",
    "                \"end_seq_token\":self._end_seq_token}\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"Returns index of a token, or <UNK> index if not present\n",
    "\n",
    "        Args:\n",
    "            token (str): Token to to find index for\n",
    "        Returns:\n",
    "            index (int): The index of the token\n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            return self._tok_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._tok_to_idx[token]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca2a184",
   "metadata": {},
   "source": [
    "### Vectorizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c358fd4a",
   "metadata": {},
   "source": [
    "Vectorizer for use with one-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06447eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "class OHVectorizer(object):\n",
    "    \"\"\"One-Hot Vectorizer\"\"\"\n",
    "    def __init__(self, narrative_vocab, injury_codes):\n",
    "        \"\"\"Args:\n",
    "            narrative_vocab (Vocabulary): Vocab for the narrative feature\n",
    "            injury_codes (Vocabulary): Injuries are already encoded as integers\n",
    "        \"\"\"\n",
    "        self.narrative_vocab = narrative_vocab\n",
    "        self.injury_codes = injury_codes\n",
    "    \n",
    "    def vectorize(self, narrative, vec_length=None):\n",
    "        \"\"\"Create one-hot encoding for the narrative\n",
    "        \n",
    "        Args:\n",
    "            narrative (str): The narrative\n",
    "        \n",
    "        Returns:\n",
    "            one_hot (np.ndarray): The one-hot encoding\n",
    "        \"\"\"\n",
    "        \n",
    "        one_hot = np.zeros(len(self.narrative_vocab), dtype=np.float32)\n",
    "        for token in narrative.split(\" \"):\n",
    "            if token not in string.punctuation:\n",
    "                one_hot[self.narrative_vocab.lookup_token(token)] = 1\n",
    "        return one_hot\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, df, cutoff=0):\n",
    "        \"\"\"Create a one-hot vectorizer from a dataframe\n",
    "        \n",
    "        Args:\n",
    "            narrative_df (pandas.DataFrame): Narrative dataframe\n",
    "            injury_code_arr (arraylike): Array of injury codes \n",
    "            \n",
    "        Returns:\n",
    "            OHVectorizer object\n",
    "        \"\"\"\n",
    "        \n",
    "        word_counter = Counter()\n",
    "        narrative_vocab = SequenceVocabulary(add_unk=True)\n",
    "        for narrative in sorted(set(df[\"NARRATIVE\"])):\n",
    "            for token in narrative.split(\" \"):\n",
    "                if token not in string.punctuation:\n",
    "                    word_counter[token] += 1\n",
    "                    \n",
    "        for word, count in word_counter.items():\n",
    "            if count > cutoff:\n",
    "                narrative_vocab.add_token(word)\n",
    "        \n",
    "        injury_codes = Vocabulary()\n",
    "        for code in sorted(set(df[\"DEGREE_INJURY_CD\"])):\n",
    "            injury_codes.add_token(code)\n",
    "        \n",
    "        return cls(narrative_vocab, injury_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aff744",
   "metadata": {},
   "source": [
    "Vectorizer for embeddings, which are to be done in the classifier cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0613aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PEVectorizer(object):\n",
    "    \"\"\"Vectorizer for use with the pretrained embeddings\"\"\"\n",
    "    def __init__(self, narrative_vocab, injury_codes):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            narrative_vocab (Vocabulary): Vocab for the narrative feature\n",
    "            injury_codes (Vocabulary): Injuries are already encoded as integers\n",
    "        \"\"\"\n",
    "        self.narrative_vocab = narrative_vocab\n",
    "        self.injury_codes = injury_codes\n",
    "    \n",
    "    def vectorize(self, narrative, vec_length=-1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            narrative (str): The space-separated narrative\n",
    "            vec_length (int): Fix length of vector\n",
    "        Returns:\n",
    "            out (np.ndarray): Vectorized narrative\n",
    "        \"\"\"\n",
    "        idx = [self.narrative_vocab.begin_seq_index]\n",
    "        idx.extend(self.narrative_vocab.lookup_token(token) for token in narrative.split(\" \"))\n",
    "        idx.append(self.narrative_vocab.end_seq_index)\n",
    "        \n",
    "        if vec_length < 0:\n",
    "            vec_length = len(idx)\n",
    "            \n",
    "        out = np.zeros(vec_length, dtype=np.int64)\n",
    "        out[:len(idx)] = idx\n",
    "        out[len(idx):] = self.narrative_vocab.mask_index\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, df, cutoff=0):\n",
    "        \"\"\"Create a vectorizer from a dataframe\n",
    "        \n",
    "        Args:\n",
    "            narrative_df (pandas.DataFrame): Narrative dataframe\n",
    "            injury_code_arr (arraylike): Array of injury codes \n",
    "        Returns:\n",
    "            PEVectorizer object\n",
    "        \"\"\"\n",
    "        word_counter = Counter()\n",
    "        narrative_vocab = SequenceVocabulary(add_unk=True)\n",
    "        for narrative in sorted(set(df[\"NARRATIVE\"])):\n",
    "            for token in narrative.split(\" \"):\n",
    "                if token not in string.punctuation:\n",
    "                    word_counter[token] += 1\n",
    "                    \n",
    "        for word, count in word_counter.items():\n",
    "            if count > cutoff:\n",
    "                narrative_vocab.add_token(word)\n",
    "        \n",
    "        injury_codes = Vocabulary()\n",
    "        for code in sorted(set(df[\"DEGREE_INJURY_CD\"])):\n",
    "            injury_codes.add_token(code)\n",
    "        \n",
    "        return cls(narrative_vocab, injury_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c8b133",
   "metadata": {},
   "source": [
    "### Feed-Forward NN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9d8734",
   "metadata": {},
   "source": [
    "A basic example of a feed-forward neural network is a simple multi-layer perceptron, with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dc7be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NarrativeFFClassifier(nn.Module):\n",
    "    \"\"\"Multilayer Perceptron classifier\"\"\"\n",
    "    def __init__(self, num_features, hidden_size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_features (int): Size of input\n",
    "            hidden_size (int): Size of hidden layer\n",
    "        \"\"\"\n",
    "        super(NarrativeFFClassifier, self).__init__()\n",
    "        \n",
    "        self.num_features = num_features\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.dense1  = nn.Linear(self.num_features, self.hidden_size)\n",
    "        self.relu    = nn.ReLU()\n",
    "        self.dense2  = nn.Linear(self.hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, inputs, apply_sigmoid=False):\n",
    "        \"\"\"Forward pass\n",
    "        Args:\n",
    "            inputs (torch.Tensor): Input data tensor, inputs.shape = (batch_size, num_features)\n",
    "            apply_sigmoid (bool): True to use sigmoid activation function\n",
    "        Returns:\n",
    "            Output tensor, tensor.shape = (batch,)\n",
    "        \"\"\"\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense2(x).squeeze()\n",
    "        if apply_sigmoid:\n",
    "            x = torch.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7617347f",
   "metadata": {},
   "source": [
    "Define arguments to be used in the first model using `Namespace`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21496e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "args = Namespace(\n",
    "    frequency_cutoff=0,\n",
    "    narrative_folder_path=\"./data/task1/\",\n",
    "    model_state_file=\"./data/task1/MLPmodel.pth\",\n",
    "    vectorizer_file=\"./data/task1/MLPvectorizer.json\",\n",
    "    save_dir=\"./data/task1/\",\n",
    "    glove_file=\"./data/glove.6B/glove.6B.100d.txt\",\n",
    "    batch_size=128,\n",
    "    early_stopping_criteria=5,\n",
    "    learning_rate=0.001,\n",
    "    num_epochs=100,\n",
    "    seed=9,\n",
    "    # Runtime options\n",
    "    cuda=True,\n",
    "    device='cuda',\n",
    "    use_glove=False,\n",
    "    embedding_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07a106d",
   "metadata": {},
   "source": [
    "Define auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41189edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def make_train_state(args):\n",
    "    return {\"epoch_index\": 0,\n",
    "            \"train_loss\": [],\n",
    "            \"train_acc\": [],\n",
    "            \"valid_loss\": [],\n",
    "            \"valid_acc\": [],\n",
    "            \"test_loss\": 1,\n",
    "            \"test_acc\": 1,\n",
    "            \"learning_rate\":args.learning_rate,\n",
    "            \"stop_early\":False,\n",
    "            \"early_stopping_step\":0,\n",
    "            \"early_stopping_best_valid\": 1e8,\n",
    "            \"model_filename\": args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Implements early stopping\n",
    "    Args:\n",
    "        args (Namespace): Main model arguments\n",
    "        model (nn.Module): Model\n",
    "        train_state (dict): Current training state\n",
    "    \"\"\"\n",
    "    # Save first model\n",
    "    if train_state[\"epoch_index\"] == 0:\n",
    "        torch.save(model.state_dict(), train_state[\"model_filename\"])\n",
    "        train_state[\"stop_early\"] = False\n",
    "    \n",
    "    # Save model if performance increase\n",
    "    if train_state[\"epoch_index\"] >= 1:\n",
    "        _, loss = train_state[\"valid_loss\"][-2:]\n",
    "        \n",
    "        # If loss increased\n",
    "        if loss >= train_state[\"early_stopping_best_valid\"]:\n",
    "            train_state[\"early_stopping_step\"] += 1\n",
    "        # If loss decreased\n",
    "        else:\n",
    "            # Save best model\n",
    "            if loss < train_state[\"early_stopping_best_valid\"]:\n",
    "                torch.save(model.state_dict(), train_state[\"model_filename\"])\n",
    "            \n",
    "            train_state[\"early_stopping_step\"] = 0\n",
    "            \n",
    "        train_state[\"stop_early\"] = train_state[\"early_stopping_step\"] >= args.early_stopping_criteria\n",
    "        \n",
    "    return train_state\n",
    "\n",
    "def compute_accuracy(y_pred, y_targ):\n",
    "    y_targ = y_targ.cpu()\n",
    "    y_pred_idx = (torch.sigmoid(y_pred)>0.5).cpu().long()\n",
    "    n_correct = torch.eq(y_pred_idx, y_targ).sum().item()\n",
    "    \n",
    "    return n_correct / len(y_pred_idx) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6adbee",
   "metadata": {},
   "source": [
    "Define the important functions, such as the classifier, the loss function and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "243bdc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_state = make_train_state(args)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "dataset = Task1Dataset.load_dataset_make_vectorizer(args.narrative_folder_path, OHVectorizer)\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "num_features = len(vectorizer.narrative_vocab)\n",
    "clf = NarrativeFFClassifier(num_features=num_features, hidden_size=num_features//2)\n",
    "clf = clf.to(args.device)\n",
    "\n",
    "loss_f = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(clf.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.5, patience=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7306a4",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50ed55e",
   "metadata": {},
   "source": [
    "Below is the actual training algorithm, which may or may not take a long time depending on how many epochs, how large the dataset is, and how fast the computer is (or whether it has a CUDA enabled GPU or not). With the default settings (100 epochs), and on the `us_data_2000.csv` dataset, it takes around 2 minutes. On the `us_data` dataset, I'd estimate it would take a very very long time on my computer, (150MB vs 1.5MB, and epochs are over 100x as many batches), but maybe a couple hours on a computer with a CUDA enabled GPU/better CPU than that is in a laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4eb928c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c054c0b1c0bb42479266e4d65d1f00eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0e3f31ce45461aa8042b74cc9aaeb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Split:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_bar = tqdm(desc=\"Epoch\", \n",
    "                 total=args.num_epochs, \n",
    "                 position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='Train Split', \n",
    "                 total=dataset.get_num_batches(args.batch_size), \n",
    "                 position=1, \n",
    "                 leave=True)\n",
    "\n",
    "for epoch_index in range(args.num_epochs):\n",
    "    train_state[\"epoch_index\"] = epoch_index\n",
    "    \n",
    "    # Training dataset\n",
    "    dataset.set_split(\"train\")\n",
    "    batch_gen = gen_batches(dataset, batch_size=args.batch_size, device=args.device)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    clf.train()\n",
    "    for batch_index, batch_dict in enumerate(batch_gen):\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Compute output\n",
    "        y_pred = clf(inputs=batch_dict[\"features\"].float())\n",
    "        # Compute loss\n",
    "        loss = loss_f(y_pred, batch_dict[\"labels\"].float())\n",
    "        loss_batch = loss.item()\n",
    "        running_loss += (loss_batch-running_loss) / (batch_index+1)\n",
    "        # Compute gradiends using loss\n",
    "        loss.backward()\n",
    "        # Use optimizer to take gradient step\n",
    "        optimizer.step()\n",
    "        # Compute accuracy\n",
    "        acc_batch = compute_accuracy(y_pred, batch_dict[\"labels\"])\n",
    "        running_acc += (acc_batch-running_acc) / (batch_index+1)\n",
    "        \n",
    "        # Update the bar\n",
    "        train_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "        train_bar.update()\n",
    "            \n",
    "    train_state[\"train_loss\"].append(running_loss)\n",
    "    train_state[\"train_acc\"].append(running_acc)\n",
    "    \n",
    "    # Validation dataset\n",
    "    dataset.set_split(\"valid\")\n",
    "    batch_gen = gen_batches(dataset, batch_size=args.batch_size, device=args.device)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    clf.eval()\n",
    "    \n",
    "    for batch_index, batch_dict in enumerate(batch_gen):\n",
    "        # Compute output\n",
    "        y_pred = clf(inputs=batch_dict[\"features\"].float())\n",
    "        # Compute loss\n",
    "        loss = loss_f(y_pred, batch_dict[\"labels\"].float())\n",
    "        loss_batch = loss.item()\n",
    "        running_loss += (loss_batch-running_loss) / (batch_index+1)\n",
    "        # Compute accuracy\n",
    "        acc_batch = compute_accuracy(y_pred, batch_dict[\"labels\"])\n",
    "        running_acc += (acc_batch-running_acc) / (batch_index+1)\n",
    "        \n",
    "    train_state[\"valid_loss\"].append(running_loss)\n",
    "    train_state[\"valid_acc\"].append(running_acc)\n",
    "    \n",
    "    train_state = update_train_state(args=args, model=clf, train_state=train_state)\n",
    "\n",
    "    scheduler.step(train_state['valid_loss'][-1])\n",
    "\n",
    "    if train_state['stop_early']:\n",
    "        print(\"stop\")\n",
    "        break\n",
    "    \n",
    "    train_bar.n=0\n",
    "    epoch_bar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a900c5dd",
   "metadata": {},
   "source": [
    "#### Evaluate model on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5125fa",
   "metadata": {},
   "source": [
    "I can basically copy and paste the above validation split from the training stage above, and set the split to `test` to get the test accuracy and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e62ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_split(\"test\")\n",
    "batch_gen = gen_batches(dataset, batch_size=args.batch_size, device=args.device)\n",
    "running_loss = 0.0\n",
    "running_acc = 0.0\n",
    "clf.eval()\n",
    "for batch_index, batch_dict in enumerate(batch_gen):\n",
    "    # Compute output\n",
    "    y_pred = clf(inputs=batch_dict[\"features\"].float())\n",
    "    # Compute loss\n",
    "    loss = loss_f(y_pred, batch_dict[\"labels\"].float())\n",
    "    loss_batch = loss.item()\n",
    "    running_loss += (loss_batch-running_loss) / (batch_index+1)\n",
    "    # Compute accuracy\n",
    "    acc_batch = compute_accuracy(y_pred, batch_dict[\"labels\"])\n",
    "    running_acc += (acc_batch-running_acc) / (batch_index+1)\n",
    "\n",
    "train_state[\"test_loss\"] = running_loss\n",
    "train_state[\"test_acc\"] = running_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d847716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 69.921875\n",
      "Test loss    : 0.8867103159427643\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test accuracy: {train_state['test_acc']}\")\n",
    "print(f\"Test loss    : {train_state['test_loss']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3468ef50",
   "metadata": {},
   "source": [
    "#### Test the model on new data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1287d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_text(text):\n",
    "    if type(text) == float:\n",
    "        print(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
    "    return text\n",
    "\n",
    "def predict_injury(narrative, clf, vectorizer, decision_threshold=0.5):\n",
    "    \"\"\"Predict the injury degree\n",
    "    Args:\n",
    "        review (str): the narrative\n",
    "        clf (NarrativeClassifier): the trained model\n",
    "        vectorizer (OHVectorizer): the one-hot vectorizer\n",
    "        decision_threshold (float): The numerical boundary which separates the rating classes\n",
    "    \"\"\"\n",
    "    narrative = preprocess_text(narrative)\n",
    "    vectorized_narr = torch.tensor(vectorizer.vectorize(narrative)).to(args.device)\n",
    "    result = clf(vectorized_narr.view(1, -1))\n",
    "    probability_value = torch.sigmoid(result).item()\n",
    "    index = 1\n",
    "    if probability_value < decision_threshold:\n",
    "        index = 0\n",
    "    return vectorizer.injury_codes.lookup_index(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5367f123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employee fell and hurt their hand -> Non-Serious Injury\n"
     ]
    }
   ],
   "source": [
    "narr = \"employee fell and hurt their hand\"\n",
    "prediction = predict_injury(narr, clf, vectorizer)\n",
    "print(\"{} -> {}\".format(narr, binary_class_dict[prediction]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd730ef6",
   "metadata": {},
   "source": [
    "#### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d502e9f7",
   "metadata": {},
   "source": [
    "Clearly the above model is not fantastic, but at around 70% accuracy on the test set it's actually not quite as bad as I'd expect. The above example of a user-inputted narrative shows that the model may be seeing something about other words that lead to less serious injuries, as I struggled to make a sentence that it would classify as a Non-Serious Injury."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b5e1d4",
   "metadata": {},
   "source": [
    "### `Conv1D` CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e510efd",
   "metadata": {},
   "source": [
    "Below is defined a basic CNN using `Conv1d` cells, for sequences. This model must take data vectorized by the `PEVectorizer` vectorizer, since it handles embeddings inside of its `__init__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7645a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NarrativeCNNClassifier(nn.Module):\n",
    "    \"\"\"Narrative CNN Classifier\"\"\"\n",
    "    def __init__(self, embedding_size, num_embeddings, num_channels, hidden_dim, num_classes, dropout_p, pretrained_embeddings=None, padding_idx=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embedding_size (int): size of the embedding vectors\n",
    "            num_embeddings (int): number of embedding vectors\n",
    "            filter_width (int): width of the convolutional kernels\n",
    "            num_channels (int): number of convolutional kernels per layer\n",
    "            hidden_dim (int): the size of the hidden dimension\n",
    "            num_classes (int): the number of classes in classification\n",
    "            dropout_p (float): a dropout parameter \n",
    "            pretrained_embeddings (numpy.array): previously trained word embeddings default is None. If provided, \n",
    "            padding_idx (int): an index representing a null position\n",
    "        \"\"\"\n",
    "        super(NarrativeCNNClassifier, self).__init__()\n",
    "        \n",
    "        if pretrained_embeddings is None:\n",
    "            self.emb = nn.Embedding(embedding_dim=embedding_size,\n",
    "                                    num_embeddings=num_embeddings,\n",
    "                                    padding_idx=padding_idx)        \n",
    "        else:\n",
    "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
    "            self.emb = nn.Embedding(embedding_dim=embedding_size,\n",
    "                                    num_embeddings=num_embeddings,\n",
    "                                    padding_idx=padding_idx,\n",
    "                                    _weight=pretrained_embeddings)\n",
    "        \n",
    "        self.model = nn.Sequential(nn.Conv1d(in_channels=embedding_size,\n",
    "                                             out_channels=num_channels,\n",
    "                                             kernel_size=3),\n",
    "                                   nn.ELU(),\n",
    "                                   nn.Conv1d(in_channels=num_channels,\n",
    "                                             out_channels=num_channels,\n",
    "                                             kernel_size=3,\n",
    "                                             stride=2),\n",
    "                                   nn.ELU(),\n",
    "                                   nn.Conv1d(in_channels=num_channels,\n",
    "                                             out_channels=num_channels,\n",
    "                                             kernel_size=3),\n",
    "                                   nn.ELU()\n",
    "                                  )\n",
    "        \n",
    "        self._dropout_p = dropout_p\n",
    "        \n",
    "        self.relu    = nn.ReLU()\n",
    "        self.dense1  = nn.Linear(num_channels, hidden_dim)\n",
    "        self.dense2  = nn.Linear(hidden_dim, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, inputs, apply_sigmoid=False):\n",
    "        \"\"\"Forward pass\n",
    "        Args:\n",
    "            inputs (torch.Tensor): Input data tensor, inputs.shape = (batch_size, batch._max_seq_len)\n",
    "            apply_sigmoid (bool): True to use sigmoid activation function\n",
    "        Returns:\n",
    "            Output tensor, tensor.shape = (batch, num_classes)\n",
    "        \"\"\"\n",
    "        # inputs = (batch size, number of features)\n",
    "        x_emb = self.emb(inputs).permute(0, 2, 1)\n",
    "        # x embedded = ()\n",
    "        \n",
    "        x = self.model(x_emb)\n",
    "        \n",
    "        rem_size = x.size(dim=2)\n",
    "        x = F.avg_pool1d(x, rem_size).squeeze(dim=2)\n",
    "        x = F.dropout(x, p=self._dropout_p)\n",
    "        \n",
    "        x = self.dense1(x)\n",
    "        x = F.dropout(x, p=self._dropout_p)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        if apply_sigmoid:\n",
    "            x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a28889a",
   "metadata": {},
   "source": [
    "Define arguments for the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37dbb38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "args = Namespace(\n",
    "    frequency_cutoff=0,\n",
    "    narrative_folder_path=\"./data/task1/\",\n",
    "    model_state_file=\"./data/task1/CNNmodel.pth\",\n",
    "    vectorizer_file=\"./data/task1/CNNvectorizer.json\",\n",
    "    save_dir=\"./data/task2/\",\n",
    "    glove_file=\"./data/glove.6B/glove.6B.100d.txt\",\n",
    "    batch_size=128,\n",
    "    early_stopping_criteria=5,\n",
    "    learning_rate=0.001,\n",
    "    num_epochs=100,\n",
    "    seed=9,\n",
    "    # Runtime options\n",
    "    cuda=True,\n",
    "    device='cuda',\n",
    "    use_glove=False,\n",
    "    embedding_size=100,\n",
    "    dropout_p=0.1,\n",
    "    num_channels=100,\n",
    "    hidden_dim=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5203ec",
   "metadata": {},
   "source": [
    "Define/Redefine some auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1deed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def make_train_state(args):\n",
    "    return {\"epoch_index\": 0,\n",
    "            \"train_loss\": [],\n",
    "            \"train_acc\": [],\n",
    "            \"valid_loss\": [],\n",
    "            \"valid_acc\": [],\n",
    "            \"test_loss\": 1,\n",
    "            \"test_acc\": 1,\n",
    "            \"learning_rate\":args.learning_rate,\n",
    "            \"stop_early\":False,\n",
    "            \"early_stopping_step\":0,\n",
    "            \"early_stopping_best_valid\": 1e8,\n",
    "            \"model_filename\": args.model_state_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfb6079",
   "metadata": {},
   "source": [
    "Since the CNN model can take embeddings, we can load predefined embeddings for the data from a file using GloVe. Below are the functions to load and prepare the embeddings for use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ce158a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove(glove_file):\n",
    "    \"\"\"Load GloVe embeddings from a file\n",
    "    Args:\n",
    "        glove_file (str): path to the glove embeddings\n",
    "    Returns:\n",
    "        list:\n",
    "            word_to_index (dict)\n",
    "            embeddings (numpy.ndarray)\n",
    "    \"\"\"\n",
    "    \n",
    "    word_to_index = {}\n",
    "    embeddings = []\n",
    "    with open(glove_file, encoding=\"utf8\") as fp:\n",
    "        for index, line in enumerate(fp):\n",
    "            line = line.split(\" \")\n",
    "            word_to_index[line[0]] = index\n",
    "            embedding_i = np.array([float(val) for val in line[1:]])\n",
    "            embeddings.append(embedding_i)\n",
    "    return word_to_index, np.stack(embeddings)\n",
    "    \n",
    "def make_embedding_matrix(glove_file, words):\n",
    "    \"\"\"Create embedding matrix for a specific set of words.\n",
    "    \n",
    "    Args:\n",
    "        glove_filepath (str): file path to the glove embeddings\n",
    "        words (list): list of words in the dataset\n",
    "    \"\"\"\n",
    "    word_to_idx, glove_embeddings = load_glove(glove_file)\n",
    "    embedding_size = glove_embeddings.shape[1]\n",
    "    \n",
    "    final_embeddings = np.zeros((len(words), embedding_size))\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        if word in word_to_idx:\n",
    "            final_embeddings[i, :] = glove_embeddings[word_to_idx[word]]\n",
    "        else:\n",
    "            embedding_i = torch.ones(1, embedding_size)\n",
    "            torch.nn.init.xavier_uniform_(embedding_i)\n",
    "            final_embeddings[i, :] = embedding_i\n",
    "\n",
    "    return final_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a57910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "args.use_glove = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66c978fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Task1Dataset.load_dataset_make_vectorizer(args.narrative_folder_path, PEVectorizer)\n",
    "vectorizer = dataset.get_vectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871b90bf",
   "metadata": {},
   "source": [
    "Here is the loading of the embeddings, which then get passed into the classifier in the next cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddb53341",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.use_glove:\n",
    "    words = vectorizer.narrative_vocab._tok_to_idx.keys()\n",
    "    embeddings = make_embedding_matrix(glove_file=args.glove_file, words=words)\n",
    "else:\n",
    "    embeddings = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e25568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = NarrativeCNNClassifier(embedding_size=args.embedding_size,\n",
    "                             num_embeddings=len(vectorizer.narrative_vocab),\n",
    "                             num_channels=args.num_channels,\n",
    "                             hidden_dim=args.hidden_dim,\n",
    "                             num_classes=1,\n",
    "                             dropout_p=args.dropout_p,\n",
    "                             pretrained_embeddings=embeddings,\n",
    "                             padding_idx=0)\n",
    "clf = clf.to(args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3708f293",
   "metadata": {},
   "source": [
    "Redefine the loss function, optimizer and a scheduler for early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86c13a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f    = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(clf.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.5, patience=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a168b4",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46e55ab",
   "metadata": {},
   "source": [
    "Similarly to the last training session, this takes about 2 minutes on my machine, and will be much quicker on most machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ce43ee1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65e560e0b3744f681aad690326565e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4f48181a00440aad959b7c81ac54f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Split:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_state = make_train_state(args)\n",
    "\n",
    "epoch_bar = tqdm(desc=\"Epoch\", \n",
    "                 total=args.num_epochs, \n",
    "                 position=0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc='Train Split', \n",
    "                 total=dataset.get_num_batches(args.batch_size), \n",
    "                 position=1, \n",
    "                 leave=True)\n",
    "\n",
    "for epoch_index in range(args.num_epochs):\n",
    "    train_state[\"epoch_index\"] = epoch_index\n",
    "    \n",
    "    # Training dataset\n",
    "    dataset.set_split(\"train\")\n",
    "    batch_gen = gen_batches(dataset, batch_size=args.batch_size, device=args.device)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    clf.train()\n",
    "    for batch_index, batch_dict in enumerate(batch_gen):\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Compute output\n",
    "        y_pred = clf(inputs=batch_dict[\"features\"]).squeeze()\n",
    "        # Compute loss\n",
    "        loss = loss_f(y_pred, batch_dict[\"labels\"].float())\n",
    "        loss_batch = loss.item()\n",
    "        running_loss += (loss_batch-running_loss) / (batch_index+1)\n",
    "        # Compute gradiends using loss\n",
    "        loss.backward()\n",
    "        # Use optimizer to take gradient step\n",
    "        optimizer.step()\n",
    "        # Compute accuracy\n",
    "        acc_batch = compute_accuracy(y_pred, batch_dict[\"labels\"])\n",
    "        running_acc += (acc_batch-running_acc) / (batch_index+1)\n",
    "        \n",
    "        # Update the bar\n",
    "        train_bar.set_postfix(loss=running_loss, acc=running_acc, epoch=epoch_index)\n",
    "        train_bar.update()\n",
    "            \n",
    "    train_state[\"train_loss\"].append(running_loss)\n",
    "    train_state[\"train_acc\"].append(running_acc)\n",
    "    \n",
    "    # Validation dataset\n",
    "    dataset.set_split(\"valid\")\n",
    "    batch_gen = gen_batches(dataset, batch_size=args.batch_size, device=args.device)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    clf.eval()\n",
    "    \n",
    "    for batch_index, batch_dict in enumerate(batch_gen):\n",
    "        # Compute output\n",
    "        y_pred = clf(inputs=batch_dict[\"features\"]).squeeze()\n",
    "        # Compute loss\n",
    "        loss = loss_f(y_pred, batch_dict[\"labels\"].float())\n",
    "        loss_batch = loss.item()\n",
    "        running_loss += (loss_batch-running_loss) / (batch_index+1)\n",
    "        # Compute accuracy\n",
    "        acc_batch = compute_accuracy(y_pred, batch_dict[\"labels\"])\n",
    "        running_acc += (acc_batch-running_acc) / (batch_index+1)\n",
    "        \n",
    "    train_state[\"valid_loss\"].append(running_loss)\n",
    "    train_state[\"valid_acc\"].append(running_acc)\n",
    "    \n",
    "    train_state = update_train_state(args=args, model=clf, train_state=train_state)\n",
    "\n",
    "    scheduler.step(train_state['valid_loss'][-1])\n",
    "\n",
    "    if train_state['stop_early']:\n",
    "        break\n",
    "        \n",
    "    train_bar.n = 0\n",
    "    epoch_bar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57145d5a",
   "metadata": {},
   "source": [
    "#### Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2670871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "dataset.set_split(\"test\")\n",
    "batch_gen = gen_batches(dataset, batch_size=args.batch_size, device=args.device)\n",
    "running_loss = 0.0\n",
    "running_acc = 0.0\n",
    "clf.eval()\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_gen):\n",
    "    # Compute output\n",
    "    y_pred = clf(inputs=batch_dict[\"features\"]).squeeze()\n",
    "    # Compute loss\n",
    "    loss = loss_f(y_pred, batch_dict[\"labels\"].float())\n",
    "    loss_batch = loss.item()\n",
    "    running_loss += (loss_batch-running_loss) / (batch_index+1)\n",
    "    # Compute accuracy\n",
    "    acc_batch = compute_accuracy(y_pred, batch_dict[\"labels\"])\n",
    "    running_acc += (acc_batch-running_acc) / (batch_index+1)\n",
    "\n",
    "train_state[\"test_loss\"] = running_loss\n",
    "train_state[\"test_acc\"] = running_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a096587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 66.796875\n",
      "Test loss    : 0.7414430379867554\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test accuracy: {train_state['test_acc']}\")\n",
    "print(f\"Test loss    : {train_state['test_loss']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa1bc09",
   "metadata": {},
   "source": [
    "### Comparison of the MLP and the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac023787",
   "metadata": {},
   "source": [
    "There are many things in the above two sections that could be improved. First of all, the hyperparameters were barely tested due to time constraints (I just wanted to get the models down as soon as possible). The optimizer and learning rate were chosen as Adam, and 0.001 as Adam is an optimizer I am familiar with and it is what is used in the labs, and the learning is typically regarded as the best all-round `lr` for Adam. Also, my computer is unable to run on the full `us_data` dataset without slowing to a crawl, so I didn't test on it.\n",
    "\n",
    "The MLP and CNN with mostly the same test accuracies and losses, but the CNN is definitely more sensetive, as sometimes it will just sit at ~36% train accuracy for the entire training loop, and give the same on the test set.\n",
    "\n",
    "I was under the impression that a CNN would be better for the data, as MLPs tend to be a little basic for something as complicated as predicting the meaning of a sentence. But clearly in my implementation of both, the MLP is a better bet than the CNN. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
